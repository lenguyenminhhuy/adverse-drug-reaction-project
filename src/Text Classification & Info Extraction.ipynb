{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "COSC2753-Assignment2-Nerveless ",
      "provenance": [],
      "collapsed_sections": [
        "r1xhy6aW7j8E"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa66d481e060439f849d13426dac1813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9765f44db35848abbf8613c475828cd0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2908553d220d4abbb19a6593e6274761",
              "IPY_MODEL_bd60208135514ebaaa2caf697a343003"
            ]
          }
        },
        "9765f44db35848abbf8613c475828cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2908553d220d4abbb19a6593e6274761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_540811d89b7d41c2b78f30c09bac96aa",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3020,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3020,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7b693afb04a41418cc8e3e8579a88dd"
          }
        },
        "bd60208135514ebaaa2caf697a343003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c172e2499852401caea3d77354241469",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11.7k/? [00:02&lt;00:00, 5.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e9663a2ab034522af0d22cd419e8b54"
          }
        },
        "540811d89b7d41c2b78f30c09bac96aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7b693afb04a41418cc8e3e8579a88dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c172e2499852401caea3d77354241469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e9663a2ab034522af0d22cd419e8b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f6afb4d38b04c24b45455052d60ae6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ced3de1e313a4172ac2c80aeee50301d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5beaf2b1ba81440aaa5544bd07586b96",
              "IPY_MODEL_01d59f9413cc4ba789de409eb114d339"
            ]
          }
        },
        "ced3de1e313a4172ac2c80aeee50301d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5beaf2b1ba81440aaa5544bd07586b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d964af6c939440396c12a6ec74eeacb",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8889a3456fa44c3ea33a73e58e39bb3e"
          }
        },
        "01d59f9413cc4ba789de409eb114d339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdaa45d7659d42d2b0377580727a076b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11.9k/? [00:00&lt;00:00, 87.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1a21b82761c47c6a8f08a8a0af8d31d"
          }
        },
        "0d964af6c939440396c12a6ec74eeacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8889a3456fa44c3ea33a73e58e39bb3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdaa45d7659d42d2b0377580727a076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1a21b82761c47c6a8f08a8a0af8d31d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3291b10a04284c3d8255a652dc8c60f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_574ba1392a77486aade81daca6c68344",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a078d85fa3f4a06ad7905e5e837f383",
              "IPY_MODEL_82b8e09706c44ae4923c772f7710247d"
            ]
          }
        },
        "574ba1392a77486aade81daca6c68344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a078d85fa3f4a06ad7905e5e837f383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a80e00bd73f948a299b1da54c8dd3892",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 306554,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 306554,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_587b85e301d74d2d81667599c2a40b62"
          }
        },
        "82b8e09706c44ae4923c772f7710247d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b878ddaaafa4a83875a934b656928dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.42M/? [00:00&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acee88c60a564096ab91e0375db577ca"
          }
        },
        "a80e00bd73f948a299b1da54c8dd3892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "587b85e301d74d2d81667599c2a40b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b878ddaaafa4a83875a934b656928dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acee88c60a564096ab91e0375db577ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fc3b571ba45428d8891fe50fc88c088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_944e04713fb443049d6ca78f351dc5f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bb5d23943c14d6aad475eff81532275",
              "IPY_MODEL_cfbcbbcfe2eb46d78e9d823341383e8d"
            ]
          }
        },
        "944e04713fb443049d6ca78f351dc5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bb5d23943c14d6aad475eff81532275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4098eb91f19c4f33803cafac0477f107",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 18007,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 18007,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be626a93f4fd499ca3c5f0076d5d3dd9"
          }
        },
        "cfbcbbcfe2eb46d78e9d823341383e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ef1d3004d13462abe8720d8fcd883c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59.7k/? [00:00&lt;00:00, 84.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fd99945be4546008e57d2d332d6ce27"
          }
        },
        "4098eb91f19c4f33803cafac0477f107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be626a93f4fd499ca3c5f0076d5d3dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ef1d3004d13462abe8720d8fcd883c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fd99945be4546008e57d2d332d6ce27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18b85bb18b644e6ca1e54478cf7f9c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d21e72bce6d442bea105b5a318054d1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6328a9bca839432d8378bbf09cd716b4",
              "IPY_MODEL_1cdc7bc61e2c4bc683fcf1091225f843"
            ]
          }
        },
        "d21e72bce6d442bea105b5a318054d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6328a9bca839432d8378bbf09cd716b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb10197b59a541169e03904138c8da53",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 867712,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 867712,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c2f60f519d44077a0b8f77988194f08"
          }
        },
        "1cdc7bc61e2c4bc683fcf1091225f843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8227b2eee2194671b5e63a148decc382",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.31M/? [00:00&lt;00:00, 11.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30df91c1127544dea4ebc1ded008cf78"
          }
        },
        "cb10197b59a541169e03904138c8da53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c2f60f519d44077a0b8f77988194f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8227b2eee2194671b5e63a148decc382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30df91c1127544dea4ebc1ded008cf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8e67e0588f74bafa757c1db239b4e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c73b12838dab4894b5752b50568d122a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_57a3c30ffaf04872a63c001c4524d5b8",
              "IPY_MODEL_f36d0856faf445f2a750b6cfcf4fe0e1"
            ]
          }
        },
        "c73b12838dab4894b5752b50568d122a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57a3c30ffaf04872a63c001c4524d5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0745965c4cbc45ae9ce4c0085bdfe0bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3ba1c610146490f9407bdd0796e9fac"
          }
        },
        "f36d0856faf445f2a750b6cfcf4fe0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfd4cf56357f4427828f7faeaa8ca55e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279/0 [00:04&lt;00:00,  4.11s/ examples]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68cb2022f8d44a5384002e990cddcf0f"
          }
        },
        "0745965c4cbc45ae9ce4c0085bdfe0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3ba1c610146490f9407bdd0796e9fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfd4cf56357f4427828f7faeaa8ca55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68cb2022f8d44a5384002e990cddcf0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RMIT University in Vietnam\n",
        "\n",
        "**Course**: COSC2753 Machine Learning\n",
        "\n",
        "**Semester**: 2021A\n",
        "\n",
        "**Assessment**: Machine Learning Project\n",
        "\n",
        "**Authors**: Le Nguyen Minh Huy - s3777280 + Nguyen Manh Triet - s3678932 \n",
        "\n",
        "**Date created**: 7/5/2021\n",
        "\n",
        "**Last updated**: 24/5/2021\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "lfChaxAHmA08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adverse Drug Reaction (ADR), as depicted from its definition, is a noxious and unintended response of a drug that occurs at normal prescribed doses used in humans for various medical purposes like diagnosis, therapy of disease and so on. Seminar research undertaken in the late 20th and early 21st century in the USA and the UK indicated that the incidence of ADRs has remained relatively unchanged overtime. For elaboration, such figures suggest that an approximate of 5% and 10% of patients may suffer from an ADR at admission, during admission or at discharge, despite various precautionary efforts. Moreover, this prevalence threat needs to be thoroughly studied due to its correlation with morbidity and mortality, which can be financially costly and pose a potential negative impact on the prescriber-patient relationship.\n",
        "\n",
        "By implementing information extraction technologies, our project aims to classify a particular contextual content and determine whether it is related to Adverse Drug Reaction or not. Specifically, we will construct a deep learning model to perform binary classification. The input for this model will be a chunk of text and the expected outcome should be a binary indicator 0 or 1, in which 1 indicates having adverse drug reaction, while 0 is the opposite. Additionally, the sequences which are classified 1 from the previous model will be hence transferred to the information extraction model, which is a Named Entity Recognition model."
      ],
      "metadata": {
        "id": "He5rKJJ0whPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification model"
      ],
      "metadata": {
        "id": "4ITyoOEY7N3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "h_PuiOfeU2qk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install datasets"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZCITvMnM8eIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install BackTranslation"
      ],
      "outputs": [],
      "metadata": {
        "id": "ROPaWO409eal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# for working with dataset\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from datasets import ClassLabel\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# oversampling data\n",
        "from BackTranslation import BackTranslation\n",
        "\n",
        "# for visualizing data \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for modelling\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, plot_roc_curve\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional, TimeDistributed, Conv1D, MaxPooling1D, Flatten\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "NQiah2YtU2Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "9Vwnxet3_btf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The datasets implemented in this model is extracted from the Dataset Card for Adverse Drug Reaction Data v2 via *Hugging Faceâ€™s dataset* API. This model uses the ***Ade_corpus_v2_classification*** instance, which is used to classify whether a sentence is ADE-related (True) or not (False), containing 33709 rows and 2 attributes."
      ],
      "metadata": {
        "id": "vv0630hl8gXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from datasets import load_dataset\n",
        "dataset_cf = load_dataset('ade_corpus_v2', 'Ade_corpus_v2_classification')"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZE76Ud2ikL40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf = pd.DataFrame(dataset_cf['train'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "uxhA_mT1XU0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "display(HTML(df_cf[:10].to_html()))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Immobilization, while Paget's bone disease was present, and perhaps enhanced activation of dihydrotachysterol by rifampicin, could have led to increased calcium-release into the circulation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Unaccountable severe hypercalcemia in a patient treated for hypoparathyroidism with dihydrotachysterol.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS: We report two cases of pseudoporphyria caused by naproxen and oxaprozin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS: We report two cases of pseudoporphyria caused by naproxen and oxaprozin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Naproxen, the most common offender, has been associated with a dimorphic clinical pattern: a PCT-like presentation and one simulating erythropoietic protoporphyria in the pediatric population.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS: A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS: A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS: A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>RESULTS: A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "5KzhZMvndgrd",
        "outputId": "9d776705-9bda-4d7c-8591-6f28d70cfc7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf = df_cf.drop_duplicates().reset_index(drop = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MK9DG6W1Un88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualize the distribution of target column (LengthOfStay)\n",
        "target_df = pd.DataFrame(df_cf['label'].value_counts()).rename(columns = {'label': 'Total value'},\n",
        "                              index = {0: 'Not-Related', \n",
        "                                       1: 'Related'}\n",
        "                              )\n",
        "target_df['Percentage'] = round(target_df['Total value']/len(df_cf) * 100, 2)\n",
        "\n",
        "fig = go.Figure(data = [go.Bar (\n",
        "    x=target_df.index.tolist(),\n",
        "    y = target_df['Percentage'].tolist(),\n",
        "    width=[0.4, 0.4],\n",
        "    marker_color = [\"#f5cb42\", '#de9b8c'])\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text = \"Percentage of medical context whether adverse drug related or not\", \n",
        "    xaxis_title = 'Class', \n",
        "    yaxis_title = 'Percentage')\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"df92fe62-ddc2-4567-81b3-ab39c9c6a765\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"df92fe62-ddc2-4567-81b3-ab39c9c6a765\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'df92fe62-ddc2-4567-81b3-ab39c9c6a765',\n",
              "                        [{\"marker\": {\"color\": [\"#f5cb42\", \"#de9b8c\"]}, \"type\": \"bar\", \"width\": [0.4, 0.4], \"x\": [\"Not-Related\", \"Related\"], \"y\": [79.56, 20.44]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Percentage of medical context whether adverse drug related or not\"}, \"xaxis\": {\"title\": {\"text\": \"Class\"}}, \"yaxis\": {\"title\": {\"text\": \"Percentage\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('df92fe62-ddc2-4567-81b3-ab39c9c6a765');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bx3APoSBnWRB",
        "outputId": "ed05a424-ee01-4c2c-f27f-01320f9cd567"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a model in an imbalanced dataset leads to a significant bias towards larger classes. Moreover, the class with fewer data points will be treated as noise and ignored during the training process. There are two main ways to balancing the datasets: oversampling and undersampling. \n",
        "\n",
        "As we lose much information using the undersampling method, the team implemented oversampling technique which helps them to have more data of the minority class. In NLP, the **back-translation** technique allows us to paraphrase each instance in the dataset. Specifically, we did translate the original corpus from English to three common languages that are* French*, *Japanese*, and *Spanish*, and then back translating them to English. To implement the technique, we have used the `BackTranslation` python package which utilizes the googletrans library and Baidu Translation API."
      ],
      "metadata": {
        "id": "GAYuYxB7nmvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle imbalanced data"
      ],
      "metadata": {
        "id": "4pCSPhDtnfdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with an **imbalanced dataset** is one of the most crucial phases to have a model with good performance. There are lots of strategies to handle the problem which could be improving the classification algorithms or balancing the dataset. Regarding balancing the training dataset, as we will lose much information if undersampling, the team decided to implement oversampling technique which helps us to have more data of the minority class.\n",
        "\n",
        "In Natural Language Processing (NLP), the **back-translation** technique allows us to paraphrase each instance in the dataset. Specifically, we will translate the original corpus from English to different common languages that are *French*, *Japanese*, and *Spanish*, and then back translating them  to English [ref]. To implement the technique, \bwe have used the BackTranslation python package which utilizes the `googletrans` library and `Baidu Translation` API."
      ],
      "metadata": {
        "id": "QTLjzS_JXoXz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trans = BackTranslation(url=[\n",
        "      'translate.google.com',\n",
        "      'translate.google.co.kr',\n",
        "    ])\n",
        "\n",
        "language_code =  ['fr','es', 'ja']"
      ],
      "outputs": [],
      "metadata": {
        "id": "lowRjMYondX7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "text_bt = []\n",
        "for language in language_code:\n",
        "  for i in range (0, len(df_cf[df_cf['label'] == 1])):\n",
        "    trans = BackTranslation(url=[\n",
        "        'translate.google.com',\n",
        "        'translate.google.co.kr',\n",
        "      ])\n",
        "    text_translate = trans.translate(df_cf['text'][i],\n",
        "                                src ='en',\n",
        "                                tmp = language)\n",
        "                    \n",
        "    result = text_translate.result_text\n",
        "    text_bt.append(result)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nlfjpgx9V-8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "labels = []\n",
        "for _ in range (0,3):\n",
        "  for i in range(0, len(df_cf[df_cf['label'] ==1])):\n",
        "    labels.append(1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "x0FewqlUk-5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf_bt = pd.DataFrame(data = {'label': labels, 'text': text_bt})"
      ],
      "outputs": [],
      "metadata": {
        "id": "n31luhTIkHAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf = df_cf.append(df_cf_bt, ignore_index=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DpLvV-GWlO-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Immobilization, while Paget's bone disease was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Unaccountable severe hypercalcemia in a patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Naproxen, the most common offender, has been a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33704</th>\n",
              "      <td>1</td>\n",
              "      <td>Reversible Non-pleureline declining palatable ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33705</th>\n",
              "      <td>1</td>\n",
              "      <td>Lithium treatment ended in 1975 for lithium po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33706</th>\n",
              "      <td>1</td>\n",
              "      <td>Eosinophilic caused by clozapine was observed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33707</th>\n",
              "      <td>1</td>\n",
              "      <td>Eyeosinospheric spheres encountered 0.2 to 61....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33708</th>\n",
              "      <td>1</td>\n",
              "      <td>The challenge with Clozapine in the history of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33709 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                               text\n",
              "0          1      Intravenous azithromycin-induced ototoxicity.\n",
              "1          1  Immobilization, while Paget's bone disease was...\n",
              "2          1  Unaccountable severe hypercalcemia in a patien...\n",
              "3          1  METHODS: We report two cases of pseudoporphyri...\n",
              "4          1  Naproxen, the most common offender, has been a...\n",
              "...      ...                                                ...\n",
              "33704      1  Reversible Non-pleureline declining palatable ...\n",
              "33705      1  Lithium treatment ended in 1975 for lithium po...\n",
              "33706      1  Eosinophilic caused by clozapine was observed ...\n",
              "33707      1  Eyeosinospheric spheres encountered 0.2 to 61....\n",
              "33708      1  The challenge with Clozapine in the history of...\n",
              "\n",
              "[33709 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5ch46gEIlTmg",
        "outputId": "ec871a30-c672-4a7e-eed7-62b068da4082"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "my_data = df_cf.to_csv('balanced_data')"
      ],
      "outputs": [],
      "metadata": {
        "id": "hd1Mxu6DpijF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load balanced dataset"
      ],
      "metadata": {
        "id": "isqjJuNWUGFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdGwyBLbAOux",
        "outputId": "bae98caf-359c-47d7-8a9e-3d25d79c90ba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf = pd.read_csv('/content/drive/MyDrive/balanced_data', index_col =0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "j7MkYMP-ARr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualize the distribution of target column (LengthOfStay)\n",
        "target_df = pd.DataFrame(df_cf['label'].value_counts()).rename(columns = {'label': 'Total value'},\n",
        "                              index = {0: 'Not-Related', \n",
        "                                       1: 'Related'}\n",
        "                              )\n",
        "target_df['Percentage'] = round(target_df['Total value']/len(df_cf) * 100, 2)\n",
        "\n",
        "fig = go.Figure(data = [go.Bar (\n",
        "    x=target_df.index.tolist(),\n",
        "    y = target_df['Percentage'].tolist(),\n",
        "    width=[0.4, 0.4],\n",
        "    marker_color = [\"#f5cb42\", '#de9b8c'])\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text = \"Percentage of medical context whether adverse drug related or not\", \n",
        "    xaxis_title = 'Class', \n",
        "    yaxis_title = 'Percentage')\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4b30c0c0-b994-43ab-893c-3a16fb8ac1f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4b30c0c0-b994-43ab-893c-3a16fb8ac1f4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4b30c0c0-b994-43ab-893c-3a16fb8ac1f4',\n",
              "                        [{\"marker\": {\"color\": [\"#f5cb42\", \"#de9b8c\"]}, \"type\": \"bar\", \"width\": [0.4, 0.4], \"x\": [\"Related\", \"Not-Related\"], \"y\": [50.68, 49.32]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Percentage of medical context whether adverse drug related or not\"}, \"xaxis\": {\"title\": {\"text\": \"Class\"}}, \"yaxis\": {\"title\": {\"text\": \"Percentage\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4b30c0c0-b994-43ab-893c-3a16fb8ac1f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "VZt81-zYlXo8",
        "outputId": "e40bac63-1888-49ac-f3a4-557888ed0cfe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf['length'] = df_cf['text'].str.split().str.len()"
      ],
      "outputs": [],
      "metadata": {
        "id": "N9OF-wpNYohz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_cf = df_cf.drop_duplicates().reset_index(drop = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q5nzWg5tZgsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Median length: \",np.median(df_cf['length']))\n",
        "print(\"Mean length: \",round(np.mean(df_cf['length']),2))\n",
        "print(\"Max length: \", np.max(df_cf['length']))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median length:  17.0\n",
            "Mean length:  18.17\n",
            "Max length:  135\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3OkiV8oUbk2",
        "outputId": "b85c4293-0c10-43be-faf9-de1c1dd44807"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning approach"
      ],
      "metadata": {
        "id": "RfYAZvcQ9_ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature extraction "
      ],
      "metadata": {
        "id": "7nRYuKXHcOvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Machine Learning algorithms can only deal with numerical data, text data needs to be converted to numbers. One of the most common ways to perform machine learning on text is representing documents in vectors, whose process is called vectorization [ref ]. Technically, there are lots of effective ways to generate text to numbers, such as label encoding, one-hot encoding, etc. However, the meaning and the relationship between words may be ignored during the training process by using these techniques since the vectors are simply discrete numbers. Thus, to deal with the issue, the team decided to use TFIDFVectorizer which enables us to emphasize the importance of words in specific documents and their relevance in other documents as well."
      ],
      "metadata": {
        "id": "_chGdEOm2_-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFIDF stands for Term Frequency - Inverse Document Frequencies, which not only aims to indicate the importance of the words in the given context but also take into account the relation to other documents from the same corpus. The algorithm is focusing on the number of times that word appears in a document and in other documents in the corpus as well. To be more specific, a word that often appears in a document has more relevance for that document, which interprets there is a higher probability that the document is about that specific word. Moreover, when a word frequently appears in lots of different documents, it would be considered as a less-important word since it is relevant for many documents from the whole set."
      ],
      "metadata": {
        "id": "TIYq_QYxSZzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectorizer = TfidfVectorizer()                                                                            "
      ],
      "outputs": [],
      "metadata": {
        "id": "VEHEDrUKa4Cm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# independent and dependent variable\n",
        "X = df_cf['text']\n",
        "y = df_cf['label']\n",
        "\n",
        "# spit dataset into three sets: training set, validation set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state = 123) \n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size = 0.2,\n",
        "                                                  random_state = 123)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jCeHeBqNUocZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train_tfidf = vectorizer.fit_transform(X_train.values)"
      ],
      "outputs": [],
      "metadata": {
        "id": "boEm_ujniDCp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train_tfidf.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21573, 19602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4AdhIHWVNTo",
        "outputId": "565f414c-73ba-4f6a-9479-0603ef55bcf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "feature_names = vectorizer.get_feature_names() \n",
        " \n",
        "#get tfidf vector for first document \n",
        "first_document_vector=X_train_tfidf[0] \n",
        " \n",
        "#print the scores \n",
        "df = pd.DataFrame(first_document_vector.T.todense(), \n",
        "                  index=feature_names, \n",
        "                  columns=[\"tfidf_score\"]) \n",
        "df.sort_values(by=[\"tfidf_score\"],ascending=False).head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pterygium</th>\n",
              "      <td>0.395878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02</th>\n",
              "      <td>0.347663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excision</th>\n",
              "      <td>0.333936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intraoperative</th>\n",
              "      <td>0.295709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.279632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>application</th>\n",
              "      <td>0.277799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minutes</th>\n",
              "      <td>0.277799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mitomycin</th>\n",
              "      <td>0.275203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>underwent</th>\n",
              "      <td>0.246094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>single</th>\n",
              "      <td>0.234924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>man</th>\n",
              "      <td>0.188120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>old</th>\n",
              "      <td>0.145578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>0.144330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for</th>\n",
              "      <td>0.112429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>with</th>\n",
              "      <td>0.077186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>0.058452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oxime</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oximetry</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oximetasoline</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oximes</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                tfidf_score\n",
              "pterygium          0.395878\n",
              "02                 0.347663\n",
              "excision           0.333936\n",
              "intraoperative     0.295709\n",
              "28                 0.279632\n",
              "application        0.277799\n",
              "minutes            0.277799\n",
              "mitomycin          0.275203\n",
              "underwent          0.246094\n",
              "single             0.234924\n",
              "man                0.188120\n",
              "old                0.145578\n",
              "year               0.144330\n",
              "for                0.112429\n",
              "with               0.077186\n",
              "of                 0.058452\n",
              "oxime              0.000000\n",
              "oximetry           0.000000\n",
              "oximetasoline      0.000000\n",
              "oximes             0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "iUl2YChwySx8",
        "outputId": "18992751-0ffe-464f-caee-a15b5a85c224"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When applying `fit_transform` to the training set, the vectorizer object has fixed the vocabulary containing in that corpus. Hence, with the validation set, we should only use `transform` function instead of utilizing the `fit_transform` as this would update our vocabulary set."
      ],
      "metadata": {
        "id": "IR6jzbLtiq8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_val_tfidf = vectorizer.transform(X_val.values)"
      ],
      "outputs": [],
      "metadata": {
        "id": "nAeQTjslij-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "pPJY3-8fqZLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". To evaluate the model on the validation set, the team chose the metrics of F1 score, a harmonic means of precision and recall. Since F1 score conveys the balance between precision and recall, it is preferable to use in some classification problem."
      ],
      "metadata": {
        "id": "Z1woRqRD8pqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) MultinomialNB "
      ],
      "metadata": {
        "id": "a7_kB0cDoY7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MultinomialNB** stands for Multinomial Naive Bayes algorithm which is a probabilistic learning method often applied in Natural Language Processing (NLP). Based on the Bayes theorem, the algorithm returns the label of a given text. Specifically, it computes the probability of each label for a particular document and then choose the result of the *highest probability* as output.\n"
      ],
      "metadata": {
        "id": "uKiL4GIYTx1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "clf_1 = MultinomialNB()\n",
        "clf_1.fit(X_train_tfidf, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDfdJFFZh51e",
        "outputId": "8a2b6d2f-cfca-4518-b09e-01deb4b43c9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred = clf_1.predict(X_val_tfidf)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9oJnZLyHiI32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.84      2612\n",
            "           1       0.83      0.89      0.86      2782\n",
            "\n",
            "    accuracy                           0.85      5394\n",
            "   macro avg       0.85      0.85      0.85      5394\n",
            "weighted avg       0.85      0.85      0.85      5394\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6vtPKv5oJIp",
        "outputId": "b218abd8-cc47-4b10-d4b3-60b8909962d0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "f1 = f1_score(y_val,y_pred)\n",
        "auc_score = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "print(f'F1 score: {round(100*f1,2)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 85.73\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5O7zZorcnVh",
        "outputId": "0752153c-16c4-42ff-b16f-db32754b58c1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualize the result \n",
        "plot_roc_curve(clf_1, X_val_tfidf, y_val) \n",
        "plt.plot([0, 1], [0, 1], color='navy', lw= 2, linestyle='--')\n",
        "plt.show()   "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gIGtcNwUj9Un",
        "outputId": "483841d9-8141-4d46-bdc3-a7e51d4e9f2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) LightGBM \n"
      ],
      "metadata": {
        "id": "8MK_cjHYu6d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LightGBM** is a gradient boosting which is currenly mostly use in classification task. Regarding tree based learning algorithm, LightGBM model grows tree vertically instead of horizontally like others, which is called tree leaf-wise. By using this algorithm, we did reduce significant loss than other level-wise algorithm as well as choose a max-delta-loss leaf to grow.\n",
        "\n",
        "Moreover, LightGBM algorithm can work fast with a large amount of data and takes lower memory to execute."
      ],
      "metadata": {
        "id": "FQmrfcXIT1dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from lightgbm import LGBMClassifier"
      ],
      "outputs": [],
      "metadata": {
        "id": "KlyXwS1Gu9TN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "clf_2 = LGBMClassifier()\n",
        "clf_2.fit(X_train_tfidf, y_train)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJTNqWbKakpw",
        "outputId": "67a60c1d-849e-4836-daa8-66772a94429c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred = clf_2.predict(X_val_tfidf)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VFMv7VcUavaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "f1 = f1_score(y_val, y_pred)\n",
        "print(f'F1 score: {round(100*f1,2)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 82.84\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6J1I920baJl",
        "outputId": "b9eea551-c0b4-4f70-a6fb-248fa0c88fd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualize the result \n",
        "plot_roc_curve(clf_2, X_val_tfidf, y_val) \n",
        "plt.plot([0, 1], [0, 1], color='navy', lw= 2, linestyle='--')\n",
        "plt.show()   "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "oAoGwTCGx25o",
        "outputId": "edf263ab-3bb7-4f9d-a135-0f26f6c6a61d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Logistic Regression"
      ],
      "metadata": {
        "id": "1Gzqn0eDIfHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression uses the logistic function as known as the sigmoid function. Logistic regression can not only predict the discrete label but also predict the probabilities of for each class based on given attributes.\n",
        "\n",
        "The sigmoid function is an S-shaped curve that can take any real number and map it into a value between 0 and 1."
      ],
      "metadata": {
        "id": "r48sSpZWT5CS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf_3 = LogisticRegression()\n",
        "clf_3.fit(X_train_tfidf, y_train)\n",
        "y_pred = clf_3.predict(X_val_tfidf)\n",
        "\n",
        "print(f'F1 score: {f1_score(y_val, y_pred)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.8671804982971858\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWxyqAN4InOX",
        "outputId": "388bded9-dc71-4caf-9219-6b205518e13f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualize the result \n",
        "plot_roc_curve(clf_3, X_val_tfidf, y_val) \n",
        "plt.plot([0, 1], [0, 1], color='navy', lw= 2, linestyle='--')\n",
        "plt.show()   "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "v-xlJeJjx8D5",
        "outputId": "5b4ce009-243e-4cee-ea1c-5d036ff4b2a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning approach"
      ],
      "metadata": {
        "id": "IlpTP47EwkWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preporcessing"
      ],
      "metadata": {
        "id": "peIg4d2N6d5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long Short-Term Memory (LSTM) which belongs to a larger category of neural networks named Recurrent Neural Network (RNN) is widely used for many NLP tasks. As the model is able to handle the long term dependencies through its complicated architecture, LSTM returns a better performance when the context is quite long. Moreover, LSTM reduces the vanishing gradient problem happening with RNN model. Therefore, the team has built a bidirectional LSTM model for `text classification` task.\n",
        "\n"
      ],
      "metadata": {
        "id": "RxyEWeXLtZwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# split dataset\n",
        "X = df_cf['text']\n",
        "y = df_cf['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Wr6Sqslb8ksT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After splitting the dataset into 3 segments, which are: training set, validation set and test set, the data will be converted into numbers by implementing tokenize technique.\n",
        "\n",
        "One of the most popular framework widely used in NLP, Keras, provides the Tokenizer function for data scientist to generate text document to numbers. Then, the output will be fitted to the CNN model.\n"
      ],
      "metadata": {
        "id": "PjD6DA6-90JN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "max_words = 5000\n",
        "max_len = max(df_cf['length'])\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "sequences_matrix = sequence.pad_sequences(sequences,\n",
        "                                          maxlen=max_len)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9DH3RFiJ7u5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN: Long-Short Term Memory"
      ],
      "metadata": {
        "id": "gHZZLJrsPTxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constructed the RNNModel function that allows us to build and add more layers. Inside the function, there is an Embedding layer to embed text to numerical data. The following layer is LSTM with the vectors' size of 64. Then, pass those vectors through the fully connected linear layer Dense with the `relu` activation function. Finally, using sigmoid function to get the probability of the sequences belonging to Adversed Drug Event (class 1).\n"
      ],
      "metadata": {
        "id": "GfrGDMYN-dbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train_model(model):\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics=[keras.metrics.Precision(),\n",
        "                        keras.metrics.Recall()]\n",
        "              )\n",
        "  model.fit(sequences_matrix,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs= 5,\n",
        "          validation_split = 0.2,\n",
        "          callbacks=[EarlyStopping(monitor='val_loss',\n",
        "                                   min_delta=0.001\n",
        "                                   )])\n",
        "\n",
        "def eval_model(model):\n",
        "  # process validate data\n",
        "\n",
        "  val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "  val_sequences_matrix = sequence.pad_sequences(val_sequences,\n",
        "                                                maxlen=max_len)\n",
        "  \n",
        "  result = model.evaluate(val_sequences_matrix,\n",
        "                        y_val)\n",
        "  print('Precision', result[1])\n",
        "  print('Recall', result[2])\n",
        "  print('F1 score', 2*result[1]*result[2]/(result[1] + result[2]))\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "sJutCbey6x76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Baseline "
      ],
      "metadata": {
        "id": "i8U5ffxWmntG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model has only one LSTM layer and two activation functions: **ReLU** and **sigmoid**."
      ],
      "metadata": {
        "id": "9jVoSpGa2npP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def LSTMbaseline():\n",
        "  activation_func = 'relu'\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(input_dim=max_words, \n",
        "                    output_dim=12,\n",
        "                    input_length=max_len)(inputs)\n",
        "  layer = LSTM(128, activation=activation_func)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "model = LSTMbaseline()\n",
        "model.summary()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_17 (Embedding)     (None, 135, 12)           60000     \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 132,321\n",
            "Trainable params: 132,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It-K3qqSmnOk",
        "outputId": "c8195d8c-1120-4fca-ca62-44c9e47239ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GtcW1t11w66Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 6s 39ms/step - loss: 0.6513 - precision_12: 0.6715 - recall_12: 0.9223\n",
            "Precision 0.6714712977409363\n",
            "Recall 0.9223010540008545\n",
            "F1 score 0.7771482357075303\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjlflH4m6Ko8",
        "outputId": "a2fbbea3-5723-459c-c3f4-a0f43a865f96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) One LSTM layer and dropout layer"
      ],
      "metadata": {
        "id": "08WAHZPXm1B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For addressing overfitting issue, a regularization technique - dropout wasapplied to the one-LSTM-layer model. We have chosen the dropout rate of 0.5."
      ],
      "metadata": {
        "id": "X_8cPAkR22Cv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def onelayer_dropout():\n",
        "  activation_func = 'relu'\n",
        "  dropout_rate = 0.5\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(input_dim=max_words, \n",
        "                    output_dim=12,\n",
        "                    input_length=max_len)(inputs)\n",
        "\n",
        "  layer = LSTM(128, activation=activation_func)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Dropout(dropout_rate)(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "model_2 = onelayer_dropout()\n",
        "model_2.summary()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_21 (Embedding)     (None, 135, 12)           60000     \n",
            "_________________________________________________________________\n",
            "lstm_26 (LSTM)               (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 132,321\n",
            "Trainable params: 132,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpG8gHISn48Z",
        "outputId": "4b358341-2b25-40c2-f3b2-57043653b2e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(model_2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "134/134 [==============================] - 53s 385ms/step - loss: 0.6809 - precision_15: 0.6240 - recall_15: 0.2071 - val_loss: 0.5398 - val_precision_15: 0.8074 - val_recall_15: 0.7212\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 50s 376ms/step - loss: 0.5561 - precision_15: 0.7999 - recall_15: 0.4200 - val_loss: 0.4707 - val_precision_15: 0.7694 - val_recall_15: 0.9178\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 51s 378ms/step - loss: 0.5142 - precision_15: 0.8597 - recall_15: 0.4314 - val_loss: 0.4139 - val_precision_15: 0.8292 - val_recall_15: 0.8648\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 51s 379ms/step - loss: 0.4831 - precision_15: 0.8885 - recall_15: 0.4558 - val_loss: 0.3778 - val_precision_15: 0.8624 - val_recall_15: 0.8294\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 51s 381ms/step - loss: 0.4673 - precision_15: 0.9052 - recall_15: 0.4634 - val_loss: 0.3947 - val_precision_15: 0.7895 - val_recall_15: 0.9343\n"
          ]
        }
      ],
      "metadata": {
        "id": "tPGeXEBRVbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e536d129-33d4-44a7-95d9-2a25c5250303"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(model_2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 7s 40ms/step - loss: 0.3891 - precision_15: 0.7985 - recall_15: 0.9372\n",
            "Precision 0.798535943031311\n",
            "Recall 0.9372431635856628\n",
            "F1 score 0.8623474618751444\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45l3xMDt7P0W",
        "outputId": "e4affb22-29dd-4e08-e387-5f1d8d96002e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Arguments\n",
        "- monitor: Quantity to be monitored. In this case, we use `val_loss` to monitor our quantity. \n",
        "\n",
        "- min_delta: Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n",
        "\n"
      ],
      "metadata": {
        "id": "-pAP3u1AWERl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Two LSTM layers with dropout"
      ],
      "metadata": {
        "id": "Ny_RxfmV5XTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The related work has proved that RNN model performance can improve thanks to the number of LSTM layers, in other words the depth. Hence, we decided to experiment with two LSTM layers with the same dropout rate which is 0.5."
      ],
      "metadata": {
        "id": "rb78i0cV28fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def twolayer_dropout():\n",
        "  activation_func = 'relu'\n",
        "  dropout_rate = 0.5\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(input_dim=max_words, \n",
        "                    output_dim=12,\n",
        "                    input_length=max_len)(inputs)\n",
        "\n",
        "  layer = LSTM(128, activation=activation_func, \n",
        "                 return_sequences=True)(layer)\n",
        "\n",
        "  layer = LSTM(256, activation=activation_func, \n",
        "               return_sequences=False)(layer)\n",
        "\n",
        "  # layer = Dense(256,name='FC1')(layer)\n",
        "  # layer = Activation(activation_func)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Dropout(dropout_rate)(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "model_3 = twolayer_dropout()\n",
        "model_3.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_23 (Embedding)     (None, 135, 12)           60000     \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 135, 128)          72192     \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 526,689\n",
            "Trainable params: 526,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzwNzAUP5a7R",
        "outputId": "48691211-5f71-4639-9431-875696523ea4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(model_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "134/134 [==============================] - 216s 2s/step - loss: 0.6871 - precision_16: 0.5218 - recall_16: 0.3472 - val_loss: 0.5402 - val_precision_16: 0.7974 - val_recall_16: 0.7514\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 216s 2s/step - loss: 0.5533 - precision_16: 0.8266 - recall_16: 0.4001 - val_loss: 0.4503 - val_precision_16: 0.8568 - val_recall_16: 0.7717\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 217s 2s/step - loss: 0.5026 - precision_16: 0.8707 - recall_16: 0.4261 - val_loss: 0.4082 - val_precision_16: 0.8388 - val_recall_16: 0.8511\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 214s 2s/step - loss: 0.4746 - precision_16: 0.8940 - recall_16: 0.4545 - val_loss: 0.3722 - val_precision_16: 0.8591 - val_recall_16: 0.8388\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 210s 2s/step - loss: 0.4595 - precision_16: 0.9054 - recall_16: 0.4595 - val_loss: 0.3667 - val_precision_16: 0.8304 - val_recall_16: 0.9074\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arRej9w85dxH",
        "outputId": "a8be9942-6424-4fdc-df3c-899e6ba23503"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(model_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 30s 180ms/step - loss: 0.3642 - precision_16: 0.8308 - recall_16: 0.9044\n",
            "Precision 0.8308167457580566\n",
            "Recall 0.9043705463409424\n",
            "F1 score 0.8660346899630812\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIXXDM1i5sfA",
        "outputId": "41a1044d-8d30-4f4d-b4f2-823bcee904de"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) Three LSTM layers with dropout\n"
      ],
      "metadata": {
        "id": "0o61Hx0crHnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspired by the high performance of Google Translate tool using seven layers of LSTM, the team stacked their model with another LSTM layer as well as the dropout layer."
      ],
      "metadata": {
        "id": "rP4GqZCF3DhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def threelayer_dropout():\n",
        "  activation_func = 'relu'\n",
        "  dropout_rate = 0.5\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(input_dim=max_words, \n",
        "                    output_dim=12,\n",
        "                    input_length=max_len)(inputs)\n",
        "\n",
        "  layer = LSTM(128, activation=activation_func, \n",
        "                 return_sequences=True)(layer)\n",
        "\n",
        "  layer = LSTM(256, activation=activation_func, \n",
        "               return_sequences=True)(layer)\n",
        "\n",
        "  layer = LSTM(256, activation=activation_func, \n",
        "               return_sequences=False)(layer)\n",
        "\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Dropout(dropout_rate)(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "model_4 = threelayer_dropout()\n",
        "model_4.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 135, 12)           60000     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 135, 128)          72192     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 135, 256)          394240    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,052,001\n",
            "Trainable params: 1,052,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40IDS9EywsUm",
        "outputId": "5b649ab9-b289-40ba-8706-250959cb1dc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(model_4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "134/134 [==============================] - 366s 3s/step - loss: 0.6932 - precision_1: 0.4892 - recall_1: 0.1107 - val_loss: 0.6531 - val_precision_1: 0.7004 - val_recall_1: 0.7300\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 374s 3s/step - loss: 0.6083 - precision_1: 0.7592 - recall_1: 0.3501 - val_loss: 0.4523 - val_precision_1: 0.7961 - val_recall_1: 0.8912\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 359s 3s/step - loss: 0.5113 - precision_1: 0.8489 - recall_1: 0.4503 - val_loss: 0.3866 - val_precision_1: 0.8633 - val_recall_1: 0.8609\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 367s 3s/step - loss: 0.4890 - precision_1: 0.8721 - recall_1: 0.4432 - val_loss: 0.3446 - val_precision_1: 0.8503 - val_recall_1: 0.9100\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 361s 3s/step - loss: 0.4603 - precision_1: 0.9056 - recall_1: 0.4660 - val_loss: 0.3669 - val_precision_1: 0.8307 - val_recall_1: 0.9238\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndZzl2aXw385",
        "outputId": "b6c3c15e-1e83-4138-9411-0b9501c3b08e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(model_4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 52s 310ms/step - loss: 0.3889 - precision_1: 0.8066 - recall_1: 0.9085\n",
            "Precision 0.806633472442627\n",
            "Recall 0.908479630947113\n",
            "F1 score 0.854532657824075\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC31T33Yw-dA",
        "outputId": "5c6202b5-b918-49ed-e519-a17ac2b4377f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5) BidirectionalLSTM"
      ],
      "metadata": {
        "id": "5BsaU99IrQjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We replaced one LSTM layer with one Bidirectional LSTM (BLSTM) layer. Although BLSTM has double memory cells compared to the LSTM layer, the text data is processed in both directions, which helps the model capture the patterns that may be fail recognized in a unidirectional LSTM.\n"
      ],
      "metadata": {
        "id": "T1nAq9Pj3KDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def bidirectional_dropout():\n",
        "  activation_func = 'relu'\n",
        "  dropout_rate = 0.5\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(input_dim=max_words, \n",
        "                    output_dim=12,\n",
        "                    input_length=max_len)(inputs)\n",
        "  layer = Bidirectional(LSTM(128, return_sequences=True))(layer)\n",
        "  layer = LSTM(64, return_sequences=False)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Dropout(dropout_rate)(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model\n",
        "\n",
        "model_5 = bidirectional_dropout()\n",
        "model_5.summary()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 135, 12)           60000     \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 135, 256)          144384    \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 64)                82176     \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 286,625\n",
            "Trainable params: 286,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2EJ76YD9Rzf",
        "outputId": "7b1f4589-dfe2-4ed4-e2b1-e5e70ec09a18"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(model_5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "134/134 [==============================] - 132s 949ms/step - loss: 0.6655 - precision_6: 0.6158 - recall_6: 0.2805 - val_loss: 0.4602 - val_precision_6: 0.8281 - val_recall_6: 0.8448\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 126s 939ms/step - loss: 0.5277 - precision_6: 0.8481 - recall_6: 0.4270 - val_loss: 0.4424 - val_precision_6: 0.8296 - val_recall_6: 0.8916\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 127s 947ms/step - loss: 0.4923 - precision_6: 0.8811 - recall_6: 0.4462 - val_loss: 0.3903 - val_precision_6: 0.8694 - val_recall_6: 0.8770\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 127s 950ms/step - loss: 0.4640 - precision_6: 0.9081 - recall_6: 0.4652 - val_loss: 0.3464 - val_precision_6: 0.8700 - val_recall_6: 0.8820\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 125s 935ms/step - loss: 0.4449 - precision_6: 0.9199 - recall_6: 0.4659 - val_loss: 0.3286 - val_precision_6: 0.8600 - val_recall_6: 0.8967\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "772K1AGh_m0y",
        "outputId": "89eb3ea7-a086-40b7-aa50-a13db7bab30c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(model_5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 12s 72ms/step - loss: 0.3515 - precision_6: 0.8410 - recall_6: 0.8894\n",
            "Precision 0.8410455584526062\n",
            "Recall 0.889428436756134\n",
            "F1 score 0.8645606213862312\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWNh68Bf_0Mb",
        "outputId": "8f8c2c9b-6307-4959-c56a-453a5080f963"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "nUQV-lVpirQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNNs have been applied to several problems in NLP and gotten remarkable results recently. Specifically, such task like sentiment analysis was enhanced in terms of the accuracy and processing time by using CNN model. As a result, we adopt CNN as one of solutions for the depicted task. Various hyperparameters testings were performed to conclude the state-of-the-art structure for text classification task."
      ],
      "metadata": {
        "id": "ERpeuU0E3OhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) CNN with dropout"
      ],
      "metadata": {
        "id": "qyVdHMjCvs5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has one convolutional layer followed by a max-pooling layer and a dropout layer having rate of 0.5 to address the overfitting problem."
      ],
      "metadata": {
        "id": "6GK-orQhkUbz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sequences_matrix.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21312, 135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4A6xp_XsfwQ",
        "outputId": "f7482364-d7e6-4ed7-a122-9506549d1774"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def CNN():\n",
        "  # inital model\n",
        "  length = 135\n",
        "  inputs = Input(shape=(length,))\n",
        "  layer = Embedding(vocab_size, 100)(inputs)\n",
        "  layer = Conv1D(filters=32, \n",
        "                 kernel_size=4, \n",
        "                 activation='relu')(layer)\n",
        "  layer = Dropout(0.5)(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "  layer = Flatten()(layer)\n",
        "  # layer = Dense(10, activation='relu')(layer)\n",
        "  layer = Dense(1, activation='sigmoid')(layer)\n",
        "  model = Model(inputs=inputs, outputs=layer)\n",
        "  model.summary()\n",
        "  return model \n"
      ],
      "outputs": [],
      "metadata": {
        "id": "qB3wLV76jSC4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cnn_1 = CNN()\n",
        "history = train_model(cnn_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 135, 100)          1986100   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 132, 32)           12832     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 132, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 66, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2112)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 2113      \n",
            "=================================================================\n",
            "Total params: 2,001,045\n",
            "Trainable params: 2,001,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "134/134 [==============================] - 13s 90ms/step - loss: 0.6752 - precision: 0.5752 - recall: 0.4262 - val_loss: 0.4405 - val_precision: 0.8487 - val_recall: 0.7735\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 12s 87ms/step - loss: 0.3435 - precision: 0.8630 - recall: 0.8473 - val_loss: 0.3428 - val_precision: 0.8650 - val_recall: 0.8662\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 12s 87ms/step - loss: 0.2306 - precision: 0.9120 - recall: 0.9189 - val_loss: 0.3236 - val_precision: 0.8528 - val_recall: 0.9008\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 12s 88ms/step - loss: 0.1863 - precision: 0.9263 - recall: 0.9352 - val_loss: 0.3147 - val_precision: 0.8769 - val_recall: 0.8672\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 12s 87ms/step - loss: 0.1421 - precision: 0.9469 - recall: 0.9538 - val_loss: 0.3194 - val_precision: 0.8613 - val_recall: 0.8962\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181INjsKqEZf",
        "outputId": "79ed2fbf-880a-4a60-b9ef-d1b3564ac096"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(cnn_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 1s 5ms/step - loss: 0.3302 - precision: 0.8529 - recall: 0.8952\n",
            "Precision 0.8529307246208191\n",
            "Recall 0.8952274322509766\n",
            "F1 score 0.8735673937609962\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6nT-ukutwan",
        "outputId": "9e35095a-d67e-4938-b592-b32f83f63d81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Deep CNN"
      ],
      "metadata": {
        "id": "RCBRH54bvjsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model contains two sets of convolutional layers followed by a max pooling layer. Moreover, after the second max pooling layer, the team has included a dropout function of 0.5 rate to prevent overfitting problem. Then, a Dense layer as known as fully connected layer was appended with the dropout function. The final layer is a single Dense layer with a SoftMax activation function."
      ],
      "metadata": {
        "id": "7y36f-vrkfvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def deep_CNN():\n",
        "  # inital model\n",
        "  length = 135\n",
        "  inputs = Input(shape=(length,))\n",
        "  layer = Embedding(vocab_size, 100)(inputs)\n",
        "  layer = Conv1D(filters=32, \n",
        "                 kernel_size=4, \n",
        "                 activation='relu')(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "  \n",
        "  layer = Conv1D(filters=32, \n",
        "                 kernel_size=4, \n",
        "                 activation='relu')(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "\n",
        "  layer = Dropout(0.5)(layer)\n",
        "\n",
        "  layer = Flatten()(layer)\n",
        "  # layer = Dense(10, activation='relu')(layer)\n",
        "  layer = Dense(1, activation='sigmoid')(layer)\n",
        "  model = Model(inputs=inputs, outputs=layer)\n",
        "  model.summary()\n",
        "  return model "
      ],
      "outputs": [],
      "metadata": {
        "id": "DEL1H-I9vv_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cnn_2 = deep_CNN()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        [(None, 135)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_30 (Embedding)     (None, 135, 100)          1981100   \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 132, 32)           12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 66, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 63, 32)            4128      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 31, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 31, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 992)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 993       \n",
            "=================================================================\n",
            "Total params: 1,999,053\n",
            "Trainable params: 1,999,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agZQfhI0v5Bn",
        "outputId": "303d3e20-da55-4967-b113-9396f9ec04b2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "history = train_model(cnn_2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "134/134 [==============================] - 12s 80ms/step - loss: 0.6730 - precision_13: 0.5508 - recall_13: 0.6216 - val_loss: 0.4538 - val_precision_13: 0.8197 - val_recall_13: 0.7678\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 10s 77ms/step - loss: 0.3944 - precision_13: 0.8359 - recall_13: 0.8198 - val_loss: 0.3860 - val_precision_13: 0.8393 - val_recall_13: 0.8264\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 10s 77ms/step - loss: 0.2668 - precision_13: 0.9022 - recall_13: 0.8888 - val_loss: 0.3810 - val_precision_13: 0.8462 - val_recall_13: 0.8246\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 10s 76ms/step - loss: 0.2005 - precision_13: 0.9198 - recall_13: 0.9250 - val_loss: 0.3973 - val_precision_13: 0.8199 - val_recall_13: 0.8730\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJEtuPMbv7j6",
        "outputId": "c9e86e35-a69f-4e04-a2a4-c8b2c9a2dedd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_result = eval_model(cnn_2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 1s 4ms/step - loss: 0.4100 - precision_13: 0.8147 - recall_13: 0.8674\n",
            "Precision 0.8147494792938232\n",
            "Recall 0.8673929572105408\n",
            "F1 score 0.8402474664381183\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsL5aQCZv-ze",
        "outputId": "bf42fc10-b2e2-48c0-fa56-fb4f76b49382"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best model"
      ],
      "metadata": {
        "id": "Z0iSMwHTM0SM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regarding Machine Learning approach, Logistic Regression gets the highest score among three Machine Learning model, 0.867 compared to 0.857 and 0.828. This model achieves a remarkable result when compared to five experiments with LSTM Deep Learning model. On the other hand, although CNN is not widely used in NLP tasks, our **CNN with dropout** model has been considered as the best one with F1 score of 0.87. The result suggests a great promise of adapting a `CNN model` in NLP field as well as balancing dataset using `back-translation`."
      ],
      "metadata": {
        "id": "DTZaIHQV5Tpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_path = '/content/drive/MyDrive/ML_A2/text-classification-model'"
      ],
      "outputs": [],
      "metadata": {
        "id": "qnrgXSbJNHLv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cnn_1.save(model_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_A2/text-classification-model/assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqaYBsu6M2Ty",
        "outputId": "86884396-e273-4f5e-fc18-5ebf71e7c339"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test final model"
      ],
      "metadata": {
        "id": "H0bj6n2S9n2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load model\n",
        "my_model = keras.models.load_model(model_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "n-IKBbgZMioC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def model_predict(input):\n",
        "  test_sequences = tokenizer.texts_to_sequences(input)\n",
        "  test_sequences_matrix = sequence.pad_sequences(test_sequences,\n",
        "                                                  maxlen=max_len)\n",
        "  prediction = my_model.predict(test_sequences_matrix)\n",
        "  threshold = 0.5\n",
        "  prediction = list(map(lambda x: 0 if x<=threshold else 1, prediction))\n",
        "  return prediction"
      ],
      "outputs": [],
      "metadata": {
        "id": "aZyJxz7D9sA6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "prediction = model_predict(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "tIFd0xsi-JMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_testing = pd.DataFrame({'text': X_test, 'label': prediction}).reset_index(drop = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "tY5iGv9yP0Pe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_testing_label_1 = df_testing[df_testing['label'] == 1]"
      ],
      "outputs": [],
      "metadata": {
        "id": "ktXWSClC-Nk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_testing_label_1.to_csv('/content/drive/MyDrive/ML_A2/data-testing-ner')"
      ],
      "outputs": [],
      "metadata": {
        "id": "UlIuZt93QeAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER model"
      ],
      "metadata": {
        "id": "lnuu4ubN8eae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "nJcUUbvciZzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.5.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87zjL7jhRrO",
        "outputId": "6b752cf5-fe02-4237-9415-58ca9c3c3f3f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsmcFL_vFaRA",
        "outputId": "c2be931a-e382-4045-d21c-0f2eb34bcc08"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-l9din8qx\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-l9din8qx\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=57e6b4a78a7bcb99b107fa4a8c019957d6ef571d67d5f2db51a12b32a3cb2fb6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xnehmmuo/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64u8eLpXkXxT",
        "outputId": "a606fdb2-0a41-422a-ddb0-9eb0e06c9d33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "from spacy.gold import biluo_tags_from_offsets\n",
        "import en_core_web_sm\n",
        "\n",
        "# for visualizing data \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow import keras\n",
        "from keras_contrib.layers import CRF"
      ],
      "outputs": [],
      "metadata": {
        "id": "8Yxy2vu1ilk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Dataset Preparation"
      ],
      "metadata": {
        "id": "7HMuAxtAc54b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "nlp = en_core_web_sm.load()\n",
        "dataset_ner = load_dataset(\n",
        "   'ade_corpus_v2', 'Ade_corpus_v2_drug_dosage_relation')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa66d481e060439f849d13426dac1813",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3020.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f6afb4d38b04c24b45455052d60ae6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1917.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading and preparing dataset ade_corpus_v2/Ade_corpus_v2_drug_dosage_relation (download: 3.62 MiB, generated: 63.21 KiB, post-processed: Unknown size, total: 3.68 MiB) to /root/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_dosage_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3291b10a04284c3d8255a652dc8c60f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=306554.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fc3b571ba45428d8891fe50fc88c088",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=18007.0, style=ProgressStyle(descriptioâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18b85bb18b644e6ca1e54478cf7f9c9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=867712.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8e67e0588f74bafa757c1db239b4e95",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rDataset ade_corpus_v2 downloaded and prepared to /root/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_dosage_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "fa66d481e060439f849d13426dac1813",
            "9765f44db35848abbf8613c475828cd0",
            "2908553d220d4abbb19a6593e6274761",
            "bd60208135514ebaaa2caf697a343003",
            "540811d89b7d41c2b78f30c09bac96aa",
            "f7b693afb04a41418cc8e3e8579a88dd",
            "c172e2499852401caea3d77354241469",
            "2e9663a2ab034522af0d22cd419e8b54",
            "8f6afb4d38b04c24b45455052d60ae6a",
            "ced3de1e313a4172ac2c80aeee50301d",
            "5beaf2b1ba81440aaa5544bd07586b96",
            "01d59f9413cc4ba789de409eb114d339",
            "0d964af6c939440396c12a6ec74eeacb",
            "8889a3456fa44c3ea33a73e58e39bb3e",
            "bdaa45d7659d42d2b0377580727a076b",
            "b1a21b82761c47c6a8f08a8a0af8d31d",
            "3291b10a04284c3d8255a652dc8c60f7",
            "574ba1392a77486aade81daca6c68344",
            "1a078d85fa3f4a06ad7905e5e837f383",
            "82b8e09706c44ae4923c772f7710247d",
            "a80e00bd73f948a299b1da54c8dd3892",
            "587b85e301d74d2d81667599c2a40b62",
            "9b878ddaaafa4a83875a934b656928dc",
            "acee88c60a564096ab91e0375db577ca",
            "3fc3b571ba45428d8891fe50fc88c088",
            "944e04713fb443049d6ca78f351dc5f6",
            "5bb5d23943c14d6aad475eff81532275",
            "cfbcbbcfe2eb46d78e9d823341383e8d",
            "4098eb91f19c4f33803cafac0477f107",
            "be626a93f4fd499ca3c5f0076d5d3dd9",
            "2ef1d3004d13462abe8720d8fcd883c5",
            "8fd99945be4546008e57d2d332d6ce27",
            "18b85bb18b644e6ca1e54478cf7f9c9b",
            "d21e72bce6d442bea105b5a318054d1e",
            "6328a9bca839432d8378bbf09cd716b4",
            "1cdc7bc61e2c4bc683fcf1091225f843",
            "cb10197b59a541169e03904138c8da53",
            "4c2f60f519d44077a0b8f77988194f08",
            "8227b2eee2194671b5e63a148decc382",
            "30df91c1127544dea4ebc1ded008cf78",
            "c8e67e0588f74bafa757c1db239b4e95",
            "c73b12838dab4894b5752b50568d122a",
            "57a3c30ffaf04872a63c001c4524d5b8",
            "f36d0856faf445f2a750b6cfcf4fe0e1",
            "0745965c4cbc45ae9ce4c0085bdfe0bd",
            "d3ba1c610146490f9407bdd0796e9fac",
            "dfd4cf56357f4427828f7faeaa8ca55e",
            "68cb2022f8d44a5384002e990cddcf0f"
          ]
        },
        "id": "V5fiOUpE8hgH",
        "outputId": "3ecb2a83-397d-48da-9b9a-942c267fb87f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_ner = pd.DataFrame(dataset_ner['train'])\n",
        "df_ner"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dosage</th>\n",
              "      <th>drug</th>\n",
              "      <th>indexes</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1500 mg/m2</td>\n",
              "      <td>methotrexate</td>\n",
              "      <td>{'drug': {'end_char': [91], 'start_char': [79]...</td>\n",
              "      <td>An episode of subacute encephalopathy after th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4 times per day</td>\n",
              "      <td>insulin</td>\n",
              "      <td>{'drug': {'end_char': [40], 'start_char': [33]...</td>\n",
              "      <td>She continued to receive regular insulin 4 tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1 drop</td>\n",
              "      <td>brimonidine</td>\n",
              "      <td>{'drug': {'end_char': [97], 'start_char': [86]...</td>\n",
              "      <td>A 5-month-old infant became lethargic and poor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200 mg</td>\n",
              "      <td>TCA</td>\n",
              "      <td>{'drug': {'end_char': [49, 166], 'start_char':...</td>\n",
              "      <td>The presented patient was treated with 200 mg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>overdose</td>\n",
              "      <td>ibuprofen</td>\n",
              "      <td>{'drug': {'end_char': [53], 'start_char': [44]...</td>\n",
              "      <td>Central nervous system manifestations of an ib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>low</td>\n",
              "      <td>alprazolam</td>\n",
              "      <td>{'drug': {'end_char': [132], 'start_char': [12...</td>\n",
              "      <td>1. Changes in the plasma cortisol level were r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>20-25 mg/d</td>\n",
              "      <td>olanzapine</td>\n",
              "      <td>{'drug': {'end_char': [117], 'start_char': [10...</td>\n",
              "      <td>We report on three patients with acute schizop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>5 mg</td>\n",
              "      <td>isosorbide dinitrate</td>\n",
              "      <td>{'drug': {'end_char': [114], 'start_char': [94...</td>\n",
              "      <td>A 65-year-old woman with angina pectoris prese...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>5 mg</td>\n",
              "      <td>isosorbide dinitrate</td>\n",
              "      <td>{'drug': {'end_char': [73], 'start_char': [53]...</td>\n",
              "      <td>In a postural challenge test after administrat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>High</td>\n",
              "      <td>phosphate</td>\n",
              "      <td>{'drug': {'end_char': [19, 67], 'start_char': ...</td>\n",
              "      <td>High-dose phosphate treatment leads to hypokal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>279 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              dosage  ...                                               text\n",
              "0         1500 mg/m2  ...  An episode of subacute encephalopathy after th...\n",
              "1    4 times per day  ...  She continued to receive regular insulin 4 tim...\n",
              "2             1 drop  ...  A 5-month-old infant became lethargic and poor...\n",
              "3             200 mg  ...  The presented patient was treated with 200 mg ...\n",
              "4           overdose  ...  Central nervous system manifestations of an ib...\n",
              "..               ...  ...                                                ...\n",
              "274              low  ...  1. Changes in the plasma cortisol level were r...\n",
              "275       20-25 mg/d  ...  We report on three patients with acute schizop...\n",
              "276             5 mg  ...  A 65-year-old woman with angina pectoris prese...\n",
              "277             5 mg  ...  In a postural challenge test after administrat...\n",
              "278             High  ...  High-dose phosphate treatment leads to hypokal...\n",
              "\n",
              "[279 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "jGMUd5rsrcA4",
        "outputId": "c5579d80-3b3d-408b-8147-7ed8fd5e97a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:** The original format of the dataset is not suitable for training in neural network as it is not presented in IOB annotation. Therefore, we have to find a workaround solution, by converting from JSON format to spaCy's BIOLOU scheme and using one of spaCy's API to make the data conversion to the preferable format. "
      ],
      "metadata": {
        "id": "YlqI7knzG0m1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Extract neccessary features of the dataset \n",
        "indexes = df_ner['indexes']\n",
        "sentences = df_ner['text']"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qw_sOvVYQVY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This function is used to convert JSON format data to spaCy's BILOU scheme\n",
        "def convert_to_spacy_format(positions, data):\n",
        "  TRAIN_DATA = []\n",
        "  for i, example in enumerate(positions):  # see example above\n",
        "\n",
        "    sentence = data[i]\n",
        "    entities = []\n",
        "\n",
        "    for entity in example:\n",
        "      label = entity.upper()\n",
        "      start_positions = (example[entity]['start_char'])\n",
        "      end_positions = (example[entity]['end_char'])\n",
        "\n",
        "      if (len(start_positions) > 0) and (len(end_positions) > 0):\n",
        "        for idx, val in enumerate(start_positions):\n",
        "          start_pos = start_positions[idx]\n",
        "          end_pos = end_positions[idx]\n",
        "        entities.append((start_pos, end_pos, label))\n",
        "    TRAIN_DATA.append((sentence, {'entities': entities}))\n",
        "  return TRAIN_DATA\n",
        "\n",
        "# This function is used to convert spaCy's BILOU scheme to the IOB tagging scheme\n",
        "def convert_to_flair_format(data, file):\n",
        "  count = 1\n",
        "  with open(file,\"w\") as f:\n",
        "    for sent, tags in data:\n",
        "        doc = nlp(sent)\n",
        "   \n",
        "        try:\n",
        "          biluo = biluo_tags_from_offsets(doc,tags['entities'])\n",
        "          for word,tag in zip(doc, biluo):\n",
        "              f.write(f\"'Sen{count}' {word} {tag}\\n\")\n",
        "          count += 1\n",
        "          f.write(\"\\n\")\n",
        "        except ValueError:\n",
        "          continue"
      ],
      "outputs": [],
      "metadata": {
        "id": "7lKZ30XPTQ6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Execute data conversion function on acquired dataset above\n",
        "samples = convert_to_spacy_format(indexes, sentences)\n",
        "\n",
        "# Additional step to convert to the desired scheme, IOB tagging format and export the final dataset into file\n",
        "convert_to_flair_format(samples, 'drug_dose_ner.txt')"
      ],
      "outputs": [],
      "metadata": {
        "id": "-nxIMIWOaFuD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peJGI9KeR6Bx",
        "outputId": "9bda972a-1a8b-48d2-9fd7-cfd673826580"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This is the final version of our dataset for the NER model, we now load it in dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/ML_A2/drug_dose_ner.txt',\n",
        "                           delimiter=\" \",\n",
        "                           names=['Sentence #','Word', 'Tag'],\n",
        "                           index_col=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mZ-TEJFZPbES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Number of sentences: \", len(df.groupby(['Sentence #'])))\n",
        "\n",
        "words = list(set(df[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "print(\"Number of unique words in the dataset: \", n_words)\n",
        "\n",
        "tags = list(set(df[\"Tag\"].values))\n",
        "print(\"Tags:\", tags)\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)\n",
        "\n",
        "print(\"The construct of the dataset\")\n",
        "df.head(n=10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences:  279\n",
            "Number of unique words in the dataset:  1584\n",
            "Tags: ['B-DRUG', 'L-DRUG', 'I-DRUG', 'U-DOSAGE', 'L-DOSAGE', 'O', '-', 'U-DRUG', 'I-DOSAGE', 'B-DOSAGE']\n",
            "Number of Labels:  10\n",
            "The construct of the dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>An</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>episode</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>subacute</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>encephalopathy</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>after</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>infusion</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Sentence #            Word Tag\n",
              "0     'Sen1'              An   O\n",
              "1     'Sen1'         episode   O\n",
              "2     'Sen1'              of   O\n",
              "3     'Sen1'        subacute   O\n",
              "4     'Sen1'  encephalopathy   O\n",
              "5     'Sen1'           after   O\n",
              "6     'Sen1'             the   O\n",
              "7     'Sen1'        infusion   O\n",
              "8     'Sen1'              of   O\n",
              "9     'Sen1'               a   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 456
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "3DvZQh6vkqQq",
        "outputId": "44126659-065c-4f91-9766-07d0c3039a84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, the tag category contains one suspicous type ('-') and it is not follow along the IOB annotation as we want (currently follow the BILOU scheme of spaCy framwork). Therefore, further preprocessing must be performed to acquire a sufficient dataset"
      ],
      "metadata": {
        "id": "-1DxxkwFkyL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df['Tag'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O           7069\n",
              "I-DOSAGE     241\n",
              "U-DRUG       231\n",
              "B-DOSAGE     196\n",
              "L-DOSAGE     196\n",
              "U-DOSAGE      73\n",
              "B-DRUG        42\n",
              "L-DRUG        42\n",
              "-             22\n",
              "I-DRUG        11\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ib1KsZCrr7b",
        "outputId": "5b8170d2-8713-4410-98c8-2d9b31915148"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# The (-) tag partakes only a unnoticable proportion of the dataset, therefore, removing it will not affect our dataset\n",
        "df.drop(df[df['Tag'] == '-'].index, inplace = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oxyo_Hd9sc_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Based upon the above result, we proceed to drop dupplicate tokens to avoid value redundancy\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1e86gDX_xjkR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Since our tagging scheme is currently spaCy's BILOU format, we want to convert it back to the \n",
        "# standard IOB tagging scheme\n",
        "def format_tag(row):\n",
        "  row = list(row)\n",
        "  for i, c in enumerate(row):\n",
        "    if c == 'L' and i == 0:\n",
        "      row[i] = 'I'\n",
        "    if c == 'U' and i == 0:\n",
        "      row[i] = 'B'\n",
        "  return ''.join(row)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e-zFzV1byOyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Apply defined function in all row of the dataframe\n",
        "df['Tag'] = df['Tag'].map(lambda row : format_tag(row))"
      ],
      "outputs": [],
      "metadata": {
        "id": "DJcZe8hzytYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprocessing, tag categories have been updated"
      ],
      "metadata": {
        "id": "DylfIDT9yw9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Number of sentences: \", len(df.groupby(['Sentence #'])))\n",
        "\n",
        "words = list(set(df[\"Word\"].values))\n",
        "total_words = list(df['Word'].values)\n",
        "total_tags = list(df['Tag'].values)\n",
        "\n",
        "n_words = len(words)\n",
        "print(\"Number of unique words in the dataset: \", n_words)\n",
        "print(\"Number of total words in the dataset: \", len(total_words))\n",
        "print(\"Number of total labels in the dataset: \", len(total_tags))\n",
        "\n",
        "tags = list(set(df[\"Tag\"].values))\n",
        "print(\"Tags:\", tags)\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)\n",
        "\n",
        "print(\"The construct of the dataset\")\n",
        "df.head(n=10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences:  279\n",
            "Number of unique words in the dataset:  1579\n",
            "Number of total words in the dataset:  7368\n",
            "Number of total labels in the dataset:  7368\n",
            "Tags: ['B-DRUG', 'I-DRUG', 'O', 'I-DOSAGE', 'B-DOSAGE']\n",
            "Number of Labels:  5\n",
            "The construct of the dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>An</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>episode</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>subacute</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>encephalopathy</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>after</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>infusion</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>'Sen1'</td>\n",
              "      <td>moderate</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence #            Word Tag\n",
              "0      'Sen1'              An   O\n",
              "1      'Sen1'         episode   O\n",
              "2      'Sen1'              of   O\n",
              "3      'Sen1'        subacute   O\n",
              "4      'Sen1'  encephalopathy   O\n",
              "5      'Sen1'           after   O\n",
              "6      'Sen1'             the   O\n",
              "7      'Sen1'        infusion   O\n",
              "9      'Sen1'               a   O\n",
              "10     'Sen1'        moderate   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "yekeqom8tJ9k",
        "outputId": "d2c9fe70-7b0c-4756-f4f7-6ed84a56e545"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n"
      ],
      "metadata": {
        "id": "HtCxGWt47pck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This function is used to plot out the distribution of each label in the dataset \n",
        "def summary(item_list, limit=None):\n",
        "  count_dict = dict(Counter(item_list))\n",
        "  count_items = sorted(count_dict.items(), key=lambda x:x[1], reverse=True)\n",
        "  print(\"Number of unique items: \", len(count_items))\n",
        "  print(\"Average count: \", round(len(item_list)/len(count_items)),\"\\n\")\n",
        "  total_items = len(item_list)\n",
        "\n",
        "  proportion_list = []\n",
        "  xlabels = []\n",
        "  \n",
        "  for i, (key, value) in enumerate(count_items):\n",
        "      if limit:\n",
        "          if i>limit:\n",
        "              break\n",
        "      proportion =  round(value*100/total_items, 2)\n",
        "      proportion_list.append(proportion)\n",
        "  return proportion_list"
      ],
      "outputs": [],
      "metadata": {
        "id": "mA5fMrl-d9Kw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "proportion_list = summary(total_tags)\n",
        "fig = go.Figure(data = [go.Bar (\n",
        "                            x = df['Tag'].unique(),\n",
        "                            y = proportion_list,\n",
        "                            width= 0.3,\n",
        "                            marker_color = [\"#f5cb42\", '#de9b8c', '#8ccfde', '#dec48c', '#9b8cde']\n",
        "                            )\n",
        "                        ])\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text = \"Percentage of all tags in the dataset\", \n",
        "    xaxis_title = 'Tag', \n",
        "    yaxis_title = 'Percentage of total Tags')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique items:  5\n",
            "Average count:  1474 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"98c25189-2ce9-4dd3-8ef2-c72f287ee4cb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"98c25189-2ce9-4dd3-8ef2-c72f287ee4cb\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '98c25189-2ce9-4dd3-8ef2-c72f287ee4cb',\n",
              "                        [{\"marker\": {\"color\": [\"#f5cb42\", \"#de9b8c\", \"#8ccfde\", \"#dec48c\", \"#9b8cde\"]}, \"type\": \"bar\", \"width\": 0.3, \"x\": [\"O\", \"B-DRUG\", \"B-DOSAGE\", \"I-DOSAGE\", \"I-DRUG\"], \"y\": [86.09, 5.84, 3.71, 3.65, 0.72]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Percentage of all tags in the dataset\"}, \"xaxis\": {\"title\": {\"text\": \"Tag\"}}, \"yaxis\": {\"title\": {\"text\": \"Percentage of total Tags\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('98c25189-2ce9-4dd3-8ef2-c72f287ee4cb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "2y5tT-yFyyPz",
        "outputId": "304ca009-80bb-442a-a77c-e938bcdcd77c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**\n",
        "As illustrated in the graph above, there is a overwhelming class imbalance. \n",
        "While O-tag partakes over 80% of the total Tags in the whole dataset, the others, decreasing in percentage from B-DRUG to I-DRUG, contribute only a unnoticable proportion. Therefore, due to this phenomena, we select macro-f1 score to be our evaluation metrics as the macro-average gives every class the same importance, and therefore better reflects how well the model performs - considering that you aim at having a model that performs well on ALL classes, including the minority classes.\n"
      ],
      "metadata": {
        "id": "bKLW01L2s01S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This class is defined to construct data to this format \n",
        "# [(Token_1, Tag_1), ..., (Token_n, Tag_n)]\"\"\"\n",
        "class GetSentence(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sentence=1\n",
        "        self.data=data\n",
        "        self.empty = False\n",
        "        function=lambda d:[(w, t) for w, t in zip(d[\"Word\"].values.tolist(),\n",
        "                                                  d[\"Tag\"].values.tolist())]\n",
        "        \n",
        "        self.group_sent = self.data.groupby(\"Sentence #\").apply(function)\n",
        "        self.all_sentences = [d for d in self.group_sent] \n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.data[self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s[\"Word\"].values.tolist(), s[\"Tag\"].values.tolist()    \n",
        "        except:\n",
        "            self.empty = True\n",
        "            return None, None"
      ],
      "outputs": [],
      "metadata": {
        "id": "-BuYo1Hp7v_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "get = GetSentence(df)\n",
        "sentences_data = get.all_sentences\n",
        "print('This is what an example sentence looks like after:')\n",
        "print(sentences_data[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is what an example sentence looks like after:\n",
            "[('An', 'O'), ('episode', 'O'), ('of', 'O'), ('subacute', 'O'), ('encephalopathy', 'O'), ('after', 'O'), ('the', 'O'), ('infusion', 'O'), ('a', 'O'), ('moderate', 'O'), ('dose', 'O'), ('methotrexate', 'B-DRUG'), ('(', 'O'), ('1500', 'B-DOSAGE'), ('mg', 'I-DOSAGE'), ('/', 'I-DOSAGE'), ('m2', 'I-DOSAGE'), (')', 'O'), ('MTX', 'O'), ('is', 'O'), ('reported', 'O'), ('in', 'O'), ('young', 'O'), ('adult', 'O'), ('with', 'O'), ('metastastic', 'O'), ('gastric', 'O'), ('cancer', 'O'), ('.', 'O')]\n"
          ]
        }
      ],
      "metadata": {
        "id": "so4OK4ht7xMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1972a1b-18f1-4099-9884-fc6597a4fd0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Examine sentences length's distribution\n",
        "lengths = list(map(lambda x: len(x), sentences_data))\n",
        "sns.displot(lengths)\n",
        "plt.xlabel(\"Number of words in a sentence\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "print(\"Median: \",np.median(lengths))\n",
        "print(\"Mean: \",round(np.mean(lengths),2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median:  26.0\n",
            "Mean:  26.41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zmFQISkoNi58",
        "outputId": "bdda32ca-562c-415f-9f99-eaa3cc4aed4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning approach"
      ],
      "metadata": {
        "id": "qhz3r0veK6SB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Inherit scikit-learn based classes approach\n",
        "Our initial baseline approach is to inherit BaseEstimator and TransformerMixin classes from scikit-learn. Those classes give the get_params and set_params methods that all Scikit-learn estimators require as well as gives the fit_transform method respectively. Altogether, we want to create a scikit-learn base classes to use with the built-in cross-validation."
      ],
      "metadata": {
        "id": "BchIzlATKNDF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# We construct a plain Python classes and inherit some of scikit-learn classes to implement their functions\n",
        "# to make a simple memory tagger \n",
        "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Expects a list of words as X and a list of tags as y.\n",
        "        voc = {}\n",
        "        self.tags = []\n",
        "        for x, t in zip(X, y):\n",
        "            if t not in self.tags:\n",
        "                self.tags.append(t)\n",
        "            if x in voc:\n",
        "                if t in voc[x]:\n",
        "                    voc[x][t] += 1\n",
        "                else:\n",
        "                    voc[x][t] = 1\n",
        "            else:\n",
        "                voc[x] = {t: 1}\n",
        "        self.memory = {}\n",
        "        for k, d in voc.items():\n",
        "            self.memory[k] = max(d, key=d.get)\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        # Predict the the tag from memory. If word is unknown, predict 'O'.\n",
        "        return [self.memory.get(x, 'O') for x in X]"
      ],
      "outputs": [],
      "metadata": {
        "id": "RsWA-i-aDbEq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tagger = MemoryTagger()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q26jlBYrGXM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tagger.fit(total_words, total_tags)"
      ],
      "outputs": [],
      "metadata": {
        "id": "G04GZWEIGy_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(tagger.predict(total_words))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'I-DRUG', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'I-DRUG', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'I-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'B-DRUG', 'I-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'I-DRUG', 'B-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'B-DOSAGE', 'O', 'B-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-DOSAGE', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joRV5g-7G1fG",
        "outputId": "237d716c-6a31-4bf9-c85a-dc23d46f4add"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tagger.tags"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-DRUG', 'B-DOSAGE', 'I-DOSAGE', 'I-DRUG']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvQLP52oHbhU",
        "outputId": "86deaca0-1971-44db-b1e6-580e7cbc4afe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "words = df[\"Word\"].values.tolist()\n",
        "tags = df[\"Tag\"].values.tolist()"
      ],
      "outputs": [],
      "metadata": {
        "id": "TeZ6i4cfIWB9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = cross_val_predict(estimator=MemoryTagger(), X=words, y=tags, cv=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "58By5aJlIYbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)\n",
        "print(report)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE       0.72      0.59      0.65       269\n",
            "      B-DRUG       0.78      0.27      0.40       273\n",
            "    I-DOSAGE       0.60      0.57      0.58       430\n",
            "      I-DRUG       0.54      0.28      0.37        53\n",
            "           O       0.92      0.96      0.94      6343\n",
            "\n",
            "    accuracy                           0.89      7368\n",
            "   macro avg       0.71      0.53      0.59      7368\n",
            "weighted avg       0.89      0.89      0.88      7368\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUfGYPZiIa4E",
        "outputId": "ed8cdb5c-53d6-4206-88dc-529232b67642"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**\n",
        "Overall, the precision is quite reasonable but the recall is quite poor.To overcome this issue, we will now introduce a simple machine learning model to predict the named entities. To achieve this, we convert the data to a simple feature vector for every word and then use a random forest to classify the words.\n"
      ],
      "metadata": {
        "id": "D2lDmEHKiwFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Using RandomForest model"
      ],
      "metadata": {
        "id": "SlkUB_mqKBCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# We define simple rules for word feature function\n",
        "def feature_map(word):\n",
        "    '''Simple feature map.'''\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word), word.isdigit(), word.isalpha()])"
      ],
      "outputs": [],
      "metadata": {
        "id": "SmcROVSjJhNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "words = [feature_map(w) for w in df[\"Word\"].values.tolist()]"
      ],
      "outputs": [],
      "metadata": {
        "id": "iWMZYN8XJmG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Making prediction on the validation set using RandomForest model with the help of cross-validation techniques to make use\n",
        "# of our humble-sized dataset\n",
        "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
        "                         X=words, y=tags, cv=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SQQheGQDJpvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)\n",
        "print(report)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE       0.57      0.18      0.27       269\n",
            "      B-DRUG       0.36      0.03      0.06       273\n",
            "    I-DOSAGE       0.38      0.02      0.04       430\n",
            "      I-DRUG       0.00      0.00      0.00        53\n",
            "           O       0.87      0.99      0.93      6343\n",
            "\n",
            "    accuracy                           0.86      7368\n",
            "   macro avg       0.44      0.24      0.26      7368\n",
            "weighted avg       0.80      0.86      0.81      7368\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZm7xE1vJsAM",
        "outputId": "92a90fe1-b03c-47e9-f932-4174d4ceafe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput is really bad, which is expected as we lack the information of each tag to make decision. To overcome this problem, we decided to employ a more sophisticated model, which is Conditional Random Field - CRF"
      ],
      "metadata": {
        "id": "CA5-8CGyHO6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Using CRF model"
      ],
      "metadata": {
        "id": "61ukK0OO1seF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Conditional Random Field (CRF) is a standard model for predicting the most likely sequence of labels that correspond to a sequence of inputs. It is a supervised learning method which has been proven to be better than the tree based models when it comes to NER. Whereas a discrete classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account; e.g., the linear chain CRF (which is popular in natural language processing) predicts sequences of labels for sequences of input samples.\n",
        "\n",
        "In order to use CRF, we will enhance the feature set and create more features which can be used by the model to predict the tags correctly. Also, we add new features such as upper, lower, digit, title etc. for each word and also consider the consecutive words in the list. In short, we try to provide a sequence of features to the model for each word - the sequence containing capitalisations, type of word(title) etc."
      ],
      "metadata": {
        "id": "dHeNC6mkfC_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# This function is inherit from sklearn-crfsuite and used to perform feature extraction with a simple baseline features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        \n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "     \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "    \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "outputs": [],
      "metadata": {
        "id": "yQQf_EdSEup5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X = [sent2features(s) for s in sentences_data]\n",
        "y = [sent2labels(s) for s in sentences_data]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "K8f_bmYVEzEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "crf = CRF(algorithm='lbfgs',\n",
        "          c1=0.1,\n",
        "          c2=0.1,\n",
        "          max_iterations=100,\n",
        "          all_possible_transitions=False)\n",
        "crf.fit(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_N6JCzvqFSC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tags = list(crf.classes_)\n",
        "tags.remove('O')\n",
        "tags"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-DRUG', 'I-DRUG', 'B-DOSAGE', 'I-DOSAGE']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS6R7b0cW0s0",
        "outputId": "0e79ceff-ac4b-49a0-e0e7-e709cc456b5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "y_pred = crf.predict(X_val)\n",
        "metrics.flat_f1_score(y_val, y_pred,\n",
        "                      average='macro', labels=tags)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6641192918689831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 420
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_vbka2yFgZ2",
        "outputId": "55b03d25-f200-4d5f-fe7e-2abb85f43d29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'I-DOSAGE', 'B-DRUG', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'I-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DOSAGE', 'O', 'O', 'B-DRUG', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'I-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['B-DRUG', 'I-DRUG', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " ['O', 'B-DOSAGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'I-DRUG',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O'],\n",
              " ['B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'I-DOSAGE',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'I-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 449
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1LZ8FyuoU1y",
        "outputId": "fc261db8-e73b-44e4-921d-207963e70cf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sorted_tags = sorted(\n",
        "    tags,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_val, y_pred, labels=sorted_tags, digits=3\n",
        "))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE      0.737     0.683     0.709        41\n",
            "    I-DOSAGE      0.619     0.565     0.591        69\n",
            "      B-DRUG      0.789     0.682     0.732        44\n",
            "      I-DRUG      0.833     0.500     0.625        10\n",
            "\n",
            "   micro avg      0.703     0.622     0.660       164\n",
            "   macro avg      0.745     0.607     0.664       164\n",
            "weighted avg      0.707     0.622     0.660       164\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOFQQTXbFg6r",
        "outputId": "89c7f0af-50a4-49e5-eef9-e5a16b919923"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('model size: {:0.2f}M'.format(crf.size_ / 1000000))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 0.09M\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNoaGaUKZ3fA",
        "outputId": "e8121a5a-3600-4b49-cd61-495d795f5c07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is actually noticeable, although the micro-f1 has not fluctuate, other metrics experiecne a noticable rise in figure, particularly those of I-DRUG tag. "
      ],
      "metadata": {
        "id": "qwVkfXBLGcwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) CRF hyperparameters optimization"
      ],
      "metadata": {
        "id": "gWx5ikfcyFN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "outputs": [],
      "metadata": {
        "id": "g4mIt1uQXwc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "crf_tuned = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
        "                        average='macro', labels=tags)\n",
        "\n",
        "# define grid search \n",
        "rs = RandomizedSearchCV(crf_tuned, params_space,\n",
        "                        cv=5,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning:\n",
            "\n",
            "From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   27.6s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.3min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
              "                                 all_possible_transitions=True, averaging=None,\n",
              "                                 c=None, c1=None, c2=None,\n",
              "                                 calibration_candidates=None,\n",
              "                                 calibration_eta=None,\n",
              "                                 calibration_max_trials=None,\n",
              "                                 calibration_rate=None,\n",
              "                                 calibration_samples=None, delta=None,\n",
              "                                 epsilon=None, error_sensitive=None, gamma=None,\n",
              "                                 keep_...\n",
              "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f7197448550>,\n",
              "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f7197504410>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring=make_scorer(flat_f1_score, average=macro, labels=['B-DRUG', 'I-DRUG', 'B-DOSAGE', 'I-DOSAGE']),\n",
              "                   verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 432
        }
      ],
      "metadata": {
        "id": "m67GXnSEx2xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c486c9-d7e6-40ce-8da3-da312f52fb4e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best params: {'c1': 0.058761573113500463, 'c2': 0.008854148643341015}\n",
            "best CV score: 0.6280446464876833\n",
            "model size: 0.08M\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOpJfLClZJSt",
        "outputId": "1300d0c4-5ac0-4d09-82b3-e153135d4502"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "crf_tuned = rs.best_estimator_\n",
        "y_pred = crf_tuned.predict(X_val)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_val, y_pred, labels=sorted_tags, digits=3\n",
        "))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE      0.757     0.683     0.718        41\n",
            "    I-DOSAGE      0.641     0.594     0.617        69\n",
            "      B-DRUG      0.763     0.659     0.707        44\n",
            "      I-DRUG      1.000     0.500     0.667        10\n",
            "\n",
            "   micro avg      0.715     0.628     0.669       164\n",
            "   macro avg      0.790     0.609     0.677       164\n",
            "weighted avg      0.724     0.628     0.669       164\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTnjnGxBZSFY",
        "outputId": "dc0bba55-6cb9-4a53-faf3-92bc5d18b5a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**: From observation, the tuned-CRF achieved outperform the baseline CRF on macro-f1 score. Moreover, jusdging from other expects, such as model size, Precision and Recall score on each tag, we can notice a slight increase in these metrics from the tuned-CRF. Therefore, within all Machine Learning model, **tuned-CRF** would be the best performance one."
      ],
      "metadata": {
        "id": "Vrpid7inZmvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning approach"
      ],
      "metadata": {
        "id": "M382wWOILeul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dictionaries of words and tags"
      ],
      "metadata": {
        "id": "bLs0oSVZD1d0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before feeding the data into the deep learning model, we have to preprocess the text.\n",
        "\n",
        "1. We will use the word2idx dictionary to convert each word to its corresponding ID and the tag2idx to perform the same task for the labels Converting words and present them in integers help reserving more memory.\n",
        "\n",
        "2. In order to feed the text input into our model (we are experimenting different approaches with the Bi-LSTM-CRF model, we have to make sure all text (sentences) must be in the same length. There are 2 more methods 2 perform this task, one is to declare the batch_size = 1 or you can declare your batch_size > 1 but with all equal-length samples at each batch. However, I choose the Padding technique as it is more elegant and clean.We ensure this using the sequence.pad_sequences() method and MAX_LEN variable. All texts longer than MAX_LEN are truncated and shorter texts are padded to get them to the same length."
      ],
      "metadata": {
        "id": "oHrhlZm0qmqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from future.utils import iteritems\n",
        "\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1 # Unknown words\n",
        "word2idx[\"PAD\"] = 0 # Padding\n",
        "\n",
        "# Vocabulary Key:token_index -> Value:word\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
        "tag2idx[\"PAD\"] = 0\n",
        "\n",
        "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
      ],
      "outputs": [],
      "metadata": {
        "id": "F-g_x_-gEMdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pad sentences\n",
        "All the neural networks require to have inputs that have the same shape and size. However, when we pre-process and use the texts as inputs for our model e.g. LSTM, not all the sentences have the same length. In other words, naturally, some of the sentences are longer or shorter. We need to have the inputs with the same size, this is where the padding is necessary."
      ],
      "metadata": {
        "id": "N4i7qNyrEVXz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "max_len = max([len(s) for s in sentences_data])\n",
        "\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences_data]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\",value=word2idx[\"PAD\"])\n",
        "\n",
        "y = [[tag2idx[w[1]] for w in s] for s in sentences_data]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "\n",
        "y = [to_categorical(i, num_classes=n_tags+1) for i in y] #n+1 for PAD\n",
        "\n",
        "# Split train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kIx3MGUaEcqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "yoJEhijZYcNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, SpatialDropout1D\n",
        "import keras as k\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "outputs": [],
      "metadata": {
        "id": "z3uE7RAdhv-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Bi-LSTM baseline with dropout"
      ],
      "metadata": {
        "id": "fUPQwvltgcmm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=n_words+2, output_dim=50, input_length=max_len)(input)  # 50-dim embedding\n",
        "model = Dropout(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)  # variational biLSTM\n",
        "out = TimeDistributed(Dense(n_tags+1, activation=\"softmax\"))(model)  # softmax output layer\n",
        "model = Model(input, out)"
      ],
      "outputs": [],
      "metadata": {
        "id": "O3BsV9JtgqQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics = [keras.metrics.Precision(),\n",
        "                        keras.metrics.Recall()])"
      ],
      "outputs": [],
      "metadata": {
        "id": "wuExjmzlgqUi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "chkpt = ModelCheckpoint(\"ner_lstm_baseline_model.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "\n",
        "# Define early stopper to monitor the fluctuation of val_loss, stop the training process if detect no further progression\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
        "\n",
        "callbacks = [chkpt]\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=np.array(y_train),\n",
        "    validation_split=0.2,\n",
        "    epochs = 10,\n",
        "    batch_size = 64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 7s 660ms/step - loss: 1.7298 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 1.3242 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.32422, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.1585 - precision_16: 0.5380 - recall_16: 0.2286 - val_loss: 0.6589 - val_precision_16: 0.9089 - val_recall_16: 0.7722\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.32422 to 0.65890, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.6195 - precision_16: 0.8956 - recall_16: 0.8052 - val_loss: 0.4924 - val_precision_16: 0.8738 - val_recall_16: 0.8548\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65890 to 0.49236, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.5052 - precision_16: 0.8706 - recall_16: 0.8463 - val_loss: 0.5199 - val_precision_16: 0.8313 - val_recall_16: 0.8075\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.49236\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.4743 - precision_16: 0.8725 - recall_16: 0.8453 - val_loss: 0.4341 - val_precision_16: 0.8932 - val_recall_16: 0.8694\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.49236 to 0.43409, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.4457 - precision_16: 0.8851 - recall_16: 0.8608 - val_loss: 0.4156 - val_precision_16: 0.8835 - val_recall_16: 0.8635\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.43409 to 0.41556, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3903 - precision_16: 0.9073 - recall_16: 0.8867 - val_loss: 0.4021 - val_precision_16: 0.8997 - val_recall_16: 0.8790\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.41556 to 0.40211, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3921 - precision_16: 0.9025 - recall_16: 0.8794 - val_loss: 0.4199 - val_precision_16: 0.8737 - val_recall_16: 0.8567\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.40211\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.3761 - precision_16: 0.9024 - recall_16: 0.8847 - val_loss: 0.3888 - val_precision_16: 0.8996 - val_recall_16: 0.8817\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.40211 to 0.38875, saving model to ner_lstm_baseline_model.h5\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3707 - precision_16: 0.9083 - recall_16: 0.8891 - val_loss: 0.4159 - val_precision_16: 0.8744 - val_recall_16: 0.8563\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.38875\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOVT1P3tjWZs",
        "outputId": "03613afb-d021-4e5e-e5ef-e0ab26d0dec9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_cat = model.predict(X_test)\n",
        "pred = np.argmax(pred_cat, axis=-1)\n",
        "y_test_true = np.argmax(y_test, -1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9HYcRutwpstY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_test_true_tag = [[idx2tag[i] for i in row] for row in y_test_true] \n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_test_true_tag)\n",
        "print(report)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE       0.00      0.00      0.00        53\n",
            "      B-DRUG       0.00      0.00      0.00        54\n",
            "    I-DOSAGE       0.00      0.00      0.00        88\n",
            "      I-DRUG       0.00      0.00      0.00        14\n",
            "           O       0.77      0.99      0.87      1268\n",
            "         PAD       0.99      0.90      0.94      1659\n",
            "\n",
            "    accuracy                           0.88      3136\n",
            "   macro avg       0.29      0.31      0.30      3136\n",
            "weighted avg       0.84      0.88      0.85      3136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW4YTLN7pxLi",
        "outputId": "b9ef70d4-61de-474a-f40d-f766eb3c6ddf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is extremely devastating as the model could not recognize any DRUG or DOSAGE tags correctly. The macro-f1 score is disappointing. The main reason in charge for this result is the the overwhelming biased between tag categories. "
      ],
      "metadata": {
        "id": "3Mqt51ljqoUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Bi-LSTM + LSTM with dropout\n",
        "In order to tackle the above issue, we add more layer, particularly LSTM layer to increase the model learning capability, to capture more information from the context"
      ],
      "metadata": {
        "id": "LopQFijFoHCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input = Input(shape=(max_len,))\n",
        "\n",
        "#Increase word_embedding_size: \n",
        "word_embedding_size = 100\n",
        "\n",
        "# Embedding Layer\n",
        "model_2 = Embedding(input_dim=n_words+2, output_dim=word_embedding_size, input_length=max_len)(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model_2 = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model_2)\n",
        "model_2 = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model_2)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "out = TimeDistributed(Dense(n_tags+1, activation=\"softmax\"))(model_2)  \n",
        "\n",
        "# out = crf(model)  # output\n",
        "model_2 = Model(input, out)"
      ],
      "outputs": [],
      "metadata": {
        "id": "pp4KYLSWEsS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model_2.compile(optimizer=adam, loss='categorical_crossentropy', \n",
        "                metrics=[keras.metrics.Precision(),\n",
        "                        keras.metrics.Recall()])\n",
        "\n",
        "model_2.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 56)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 56, 100)           158100    \n",
            "_________________________________________________________________\n",
            "bidirectional_27 (Bidirectio (None, 56, 200)           160800    \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 56, 200)           320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_27 (TimeDis (None, 56, 6)             1206      \n",
            "=================================================================\n",
            "Total params: 640,906\n",
            "Trainable params: 640,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "j3v1WN3QHYJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a2cb42-7da7-480e-f0b4-6494edcc5062"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Saving the best model only\n",
        "filepath=\"ner_stacked_bi_lstm_model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit the best model\n",
        "history = model_2.fit(X_train, np.array(y_train), batch_size=128, epochs=20, validation_split=0.2, verbose=1, callbacks=callbacks_list)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 12s 2s/step - loss: 1.7731 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 1.5879 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.58794, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 2s 774ms/step - loss: 1.5896 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 1.3640 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.58794 to 1.36402, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 2s 767ms/step - loss: 1.3837 - precision_18: 0.6667 - recall_18: 0.0146 - val_loss: 1.1042 - val_precision_18: 1.0000 - val_recall_18: 0.4218\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.36402 to 1.10424, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 2s 748ms/step - loss: 1.1531 - precision_18: 1.0000 - recall_18: 0.3793 - val_loss: 0.8881 - val_precision_18: 1.0000 - val_recall_18: 0.5413\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.10424 to 0.88811, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 2s 775ms/step - loss: 0.9652 - precision_18: 0.9893 - recall_18: 0.4955 - val_loss: 0.8206 - val_precision_18: 0.8949 - val_recall_18: 0.5611\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.88811 to 0.82061, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 2s 751ms/step - loss: 0.8859 - precision_18: 0.8785 - recall_18: 0.5215 - val_loss: 0.7892 - val_precision_18: 0.8559 - val_recall_18: 0.5611\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.82061 to 0.78918, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 2s 755ms/step - loss: 0.8424 - precision_18: 0.8510 - recall_18: 0.5193 - val_loss: 0.6958 - val_precision_18: 0.9200 - val_recall_18: 0.5611\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.78918 to 0.69576, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 2s 771ms/step - loss: 0.7369 - precision_18: 0.9339 - recall_18: 0.5227 - val_loss: 0.6387 - val_precision_18: 0.9964 - val_recall_18: 0.5544\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.69576 to 0.63869, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 2s 763ms/step - loss: 0.6954 - precision_18: 0.9959 - recall_18: 0.5040 - val_loss: 0.6113 - val_precision_18: 0.9595 - val_recall_18: 0.5825\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.63869 to 0.61132, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 2s 781ms/step - loss: 0.6685 - precision_18: 0.9483 - recall_18: 0.5362 - val_loss: 0.5477 - val_precision_18: 0.9227 - val_recall_18: 0.6683\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.61132 to 0.54766, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 2s 766ms/step - loss: 0.5861 - precision_18: 0.9106 - recall_18: 0.6426 - val_loss: 0.4758 - val_precision_18: 0.9327 - val_recall_18: 0.7869\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.54766 to 0.47582, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 2s 765ms/step - loss: 0.5105 - precision_18: 0.9207 - recall_18: 0.7687 - val_loss: 0.4854 - val_precision_18: 0.8979 - val_recall_18: 0.8060\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.47582\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 2s 770ms/step - loss: 0.4966 - precision_18: 0.9097 - recall_18: 0.8101 - val_loss: 0.4546 - val_precision_18: 0.9091 - val_recall_18: 0.8373\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.47582 to 0.45457, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 2s 801ms/step - loss: 0.4811 - precision_18: 0.9009 - recall_18: 0.8249 - val_loss: 0.4471 - val_precision_18: 0.9108 - val_recall_18: 0.8504\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.45457 to 0.44708, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 2s 780ms/step - loss: 0.4631 - precision_18: 0.9055 - recall_18: 0.8422 - val_loss: 0.4407 - val_precision_18: 0.9094 - val_recall_18: 0.8599\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.44708 to 0.44074, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 2s 767ms/step - loss: 0.4407 - precision_18: 0.9138 - recall_18: 0.8560 - val_loss: 0.4172 - val_precision_18: 0.9133 - val_recall_18: 0.8655\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.44074 to 0.41724, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 2s 758ms/step - loss: 0.4165 - precision_18: 0.9171 - recall_18: 0.8646 - val_loss: 0.3887 - val_precision_18: 0.9208 - val_recall_18: 0.8762\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.41724 to 0.38867, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 2s 762ms/step - loss: 0.3993 - precision_18: 0.9132 - recall_18: 0.8652 - val_loss: 0.3718 - val_precision_18: 0.9227 - val_recall_18: 0.8810\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.38867 to 0.37178, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 2s 764ms/step - loss: 0.3789 - precision_18: 0.9189 - recall_18: 0.8739 - val_loss: 0.3608 - val_precision_18: 0.9224 - val_recall_18: 0.8825\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.37178 to 0.36075, saving model to ner_stacked_bi_lstm_model.hdf5\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 2s 770ms/step - loss: 0.3661 - precision_18: 0.9208 - recall_18: 0.8786 - val_loss: 0.3551 - val_precision_18: 0.9180 - val_recall_18: 0.8802\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.36075 to 0.35506, saving model to ner_stacked_bi_lstm_model.hdf5\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4y88ny-CfiI",
        "outputId": "4a70b068-dfb8-48dc-c12f-59bec0b93db8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_cat = model_2.predict(X_test)\n",
        "pred = np.argmax(pred_cat, axis=-1)\n",
        "y_test_true = np.argmax(y_test, -1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SDWA-ogiCk8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_test_true_tag = [[idx2tag[i] for i in row] for row in y_test_true] \n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_test_true_tag)\n",
        "print(report)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    B-DOSAGE       0.00      0.00      0.00        53\n",
            "      B-DRUG       0.00      0.00      0.00        54\n",
            "    I-DOSAGE       0.00      0.00      0.00        88\n",
            "      I-DRUG       0.00      0.00      0.00        14\n",
            "           O       0.85      0.95      0.90      1268\n",
            "         PAD       0.96      1.00      0.98      1659\n",
            "\n",
            "    accuracy                           0.91      3136\n",
            "   macro avg       0.30      0.33      0.31      3136\n",
            "weighted avg       0.86      0.91      0.88      3136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALu2s2dkqVrV",
        "outputId": "22bb5d6e-04ff-4fd4-a3ed-d30566148ae7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is not improving at all, although there is a slight increase in macro f1, from 0.3 to 0.31. However, others metrics from all tags remain unchanged, which mean the model is not sufficent enough to capture those information."
      ],
      "metadata": {
        "id": "owYPUlREJ4Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ultimate Judgement\n",
        "Based on the performance of each approaches towards the chosen metrics - macro-f1 score. We finally came to the conclusion that the tuned-CRF is the best model to perform the named entity recognition task on the *Ade_corpus_v2_drug_dosage_relation* dataset. The model itself acquire 65,8% on macro-f1, which is not the best figure comparing to other state-of-the-art solution in the industry.\n",
        "\n",
        "However, since our dataset structure is not containing any POS-tag for each word, so it may have a noticeable affect on the learning capability of the CRF model. Because POS-tag concerns about the context information in a sentence, it might help CRF preserve more information rather than just remembering the word itself. For futreu improvement, we definitely need to construct and expand our dataset in order to increase the model performance."
      ],
      "metadata": {
        "id": "eqKVaILDav80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best model export and testing"
      ],
      "metadata": {
        "id": "o7LmVdP7bjD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_path = '/content/drive/MyDrive/ML_A2/ner-model'"
      ],
      "outputs": [],
      "metadata": {
        "id": "7JuEnu8guHDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "pickle.dump(crf_tuned, open(model_path, 'wb')) "
      ],
      "outputs": [],
      "metadata": {
        "id": "I8Zlt9N-cVqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load the model from disk\n",
        "ner_model = pickle.load(open(model_path, 'rb'))"
      ],
      "outputs": [],
      "metadata": {
        "id": "NuUylIp-cZjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Our NER model information\n",
        "ner_model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning:\n",
            "\n",
            "From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.058761573113500463, c2=0.008854148643341015,\n",
              "    calibration_candidates=None, calibration_eta=None,\n",
              "    calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiE581fhdH1K",
        "outputId": "767ed379-57b1-43ed-a815-9b1e3c4c696e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/ML_A2/data-testing-ner')\n",
        "test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A prerenal component could have contributed to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Hypersensitivity to zonizamide has been confir...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>The three reported cases demonstrate that trog...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Epstein Bar virus-related lymphocyte prolifera...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Methotrexate is an effective but potentially t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3461</th>\n",
              "      <td>6651</td>\n",
              "      <td>Fulminating hepatic failure developed in a 24-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3462</th>\n",
              "      <td>6654</td>\n",
              "      <td>He has developed recurring skin rash, fever, h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>6655</td>\n",
              "      <td>Hyperammonia induced by carbamazepine.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>6656</td>\n",
              "      <td>Atypical endometriosis may act as a precancero...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>6659</td>\n",
              "      <td>As a result, we identified total 11 patients w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3466 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                               text  label\n",
              "0              0  A prerenal component could have contributed to...      1\n",
              "1              3  Hypersensitivity to zonizamide has been confir...      1\n",
              "2              4  The three reported cases demonstrate that trog...      1\n",
              "3              5  Epstein Bar virus-related lymphocyte prolifera...      1\n",
              "4             10  Methotrexate is an effective but potentially t...      1\n",
              "...          ...                                                ...    ...\n",
              "3461        6651  Fulminating hepatic failure developed in a 24-...      1\n",
              "3462        6654  He has developed recurring skin rash, fever, h...      1\n",
              "3463        6655             Hyperammonia induced by carbamazepine.      1\n",
              "3464        6656  Atypical endometriosis may act as a precancero...      1\n",
              "3465        6659  As a result, we identified total 11 patients w...      1\n",
              "\n",
              "[3466 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "IJ0blORldMUy",
        "outputId": "74a752cc-f14c-400b-c27c-b1ac68cf077c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define a customize word2feature function to test\n",
        "def word2features_cus(sent, i):\n",
        "    word = sent[i]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        \n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "     \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "    \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features_cus(sent):\n",
        "    return [word2features_cus(sent, i) for i in range(len(sent))]"
      ],
      "outputs": [],
      "metadata": {
        "id": "nWdABluimZL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# For the purpose of the testing, we only make prediction on the first 5 sentences of the testing dataset\n",
        "sent_list = test['text'].sample(10).tolist()\n",
        "sent_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Eboprofen rarely causes adverse reactions of gastrointestinal tract, but is involved in systemic and local side effects in lupus patients.',\n",
              " 'To our knowledge, this recurrence of amiodarone pulmonary toxicity has not been previously informed.',\n",
              " 'We describe the development of cutaneous scleroderm in 3 patients coinciding with the use of low cumulative low dose bleomycin less than 100 U.',\n",
              " 'Only few reports exist on iodine-induced hypothyroidism after a single injection of the iodized radiopaque dye Lipiodol.',\n",
              " 'A fatal case of theophylline intoxication.',\n",
              " 'Meeting of granulocytosis, eosinophilic, skin reaction and hepatitis, has been reported in Propylthiova (PTU) therapy for tyrotoxycycles in black women aged 47.',\n",
              " 'As a result, Amantadine has been permanently disturbed and the cornea has renewed again.',\n",
              " 'The most likely cause of hepatic insufficiency in this patient was, therefore, clarithromycin, which is subjected to a hepatic metabolism and has been reported that it causes fulminating liver failure.',\n",
              " 'The mechanism of decrease in potassium plasma induced by phosphate treatment was investigated in a 24-year hypertensive patient with hypophosphatemic osteomalacia, who was the youngest of four patients, who belonged to a number of 23 numbers of five generations.',\n",
              " 'It has been diagnosed with possible serotonin syndrome; its symptoms resolved after stopping clomipramine but before Clozapine has been restarted eight days later.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 493
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N30lWShdXL7",
        "outputId": "8b1cf3f9-f723-4b72-a255-e13bbde81420"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Segmentate a sentence into sequence of words and create a list to store all of those sequences\n",
        "sent = []\n",
        "for s in sent_list:\n",
        "  tmp = s.split()\n",
        "  sent.append(tmp)\n",
        "sent"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Eboprofen',\n",
              "  'rarely',\n",
              "  'causes',\n",
              "  'adverse',\n",
              "  'reactions',\n",
              "  'of',\n",
              "  'gastrointestinal',\n",
              "  'tract,',\n",
              "  'but',\n",
              "  'is',\n",
              "  'involved',\n",
              "  'in',\n",
              "  'systemic',\n",
              "  'and',\n",
              "  'local',\n",
              "  'side',\n",
              "  'effects',\n",
              "  'in',\n",
              "  'lupus',\n",
              "  'patients.'],\n",
              " ['To',\n",
              "  'our',\n",
              "  'knowledge,',\n",
              "  'this',\n",
              "  'recurrence',\n",
              "  'of',\n",
              "  'amiodarone',\n",
              "  'pulmonary',\n",
              "  'toxicity',\n",
              "  'has',\n",
              "  'not',\n",
              "  'been',\n",
              "  'previously',\n",
              "  'informed.'],\n",
              " ['We',\n",
              "  'describe',\n",
              "  'the',\n",
              "  'development',\n",
              "  'of',\n",
              "  'cutaneous',\n",
              "  'scleroderm',\n",
              "  'in',\n",
              "  '3',\n",
              "  'patients',\n",
              "  'coinciding',\n",
              "  'with',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'low',\n",
              "  'cumulative',\n",
              "  'low',\n",
              "  'dose',\n",
              "  'bleomycin',\n",
              "  'less',\n",
              "  'than',\n",
              "  '100',\n",
              "  'U.'],\n",
              " ['Only',\n",
              "  'few',\n",
              "  'reports',\n",
              "  'exist',\n",
              "  'on',\n",
              "  'iodine-induced',\n",
              "  'hypothyroidism',\n",
              "  'after',\n",
              "  'a',\n",
              "  'single',\n",
              "  'injection',\n",
              "  'of',\n",
              "  'the',\n",
              "  'iodized',\n",
              "  'radiopaque',\n",
              "  'dye',\n",
              "  'Lipiodol.'],\n",
              " ['A', 'fatal', 'case', 'of', 'theophylline', 'intoxication.'],\n",
              " ['Meeting',\n",
              "  'of',\n",
              "  'granulocytosis,',\n",
              "  'eosinophilic,',\n",
              "  'skin',\n",
              "  'reaction',\n",
              "  'and',\n",
              "  'hepatitis,',\n",
              "  'has',\n",
              "  'been',\n",
              "  'reported',\n",
              "  'in',\n",
              "  'Propylthiova',\n",
              "  '(PTU)',\n",
              "  'therapy',\n",
              "  'for',\n",
              "  'tyrotoxycycles',\n",
              "  'in',\n",
              "  'black',\n",
              "  'women',\n",
              "  'aged',\n",
              "  '47.'],\n",
              " ['As',\n",
              "  'a',\n",
              "  'result,',\n",
              "  'Amantadine',\n",
              "  'has',\n",
              "  'been',\n",
              "  'permanently',\n",
              "  'disturbed',\n",
              "  'and',\n",
              "  'the',\n",
              "  'cornea',\n",
              "  'has',\n",
              "  'renewed',\n",
              "  'again.'],\n",
              " ['The',\n",
              "  'most',\n",
              "  'likely',\n",
              "  'cause',\n",
              "  'of',\n",
              "  'hepatic',\n",
              "  'insufficiency',\n",
              "  'in',\n",
              "  'this',\n",
              "  'patient',\n",
              "  'was,',\n",
              "  'therefore,',\n",
              "  'clarithromycin,',\n",
              "  'which',\n",
              "  'is',\n",
              "  'subjected',\n",
              "  'to',\n",
              "  'a',\n",
              "  'hepatic',\n",
              "  'metabolism',\n",
              "  'and',\n",
              "  'has',\n",
              "  'been',\n",
              "  'reported',\n",
              "  'that',\n",
              "  'it',\n",
              "  'causes',\n",
              "  'fulminating',\n",
              "  'liver',\n",
              "  'failure.'],\n",
              " ['The',\n",
              "  'mechanism',\n",
              "  'of',\n",
              "  'decrease',\n",
              "  'in',\n",
              "  'potassium',\n",
              "  'plasma',\n",
              "  'induced',\n",
              "  'by',\n",
              "  'phosphate',\n",
              "  'treatment',\n",
              "  'was',\n",
              "  'investigated',\n",
              "  'in',\n",
              "  'a',\n",
              "  '24-year',\n",
              "  'hypertensive',\n",
              "  'patient',\n",
              "  'with',\n",
              "  'hypophosphatemic',\n",
              "  'osteomalacia,',\n",
              "  'who',\n",
              "  'was',\n",
              "  'the',\n",
              "  'youngest',\n",
              "  'of',\n",
              "  'four',\n",
              "  'patients,',\n",
              "  'who',\n",
              "  'belonged',\n",
              "  'to',\n",
              "  'a',\n",
              "  'number',\n",
              "  'of',\n",
              "  '23',\n",
              "  'numbers',\n",
              "  'of',\n",
              "  'five',\n",
              "  'generations.'],\n",
              " ['It',\n",
              "  'has',\n",
              "  'been',\n",
              "  'diagnosed',\n",
              "  'with',\n",
              "  'possible',\n",
              "  'serotonin',\n",
              "  'syndrome;',\n",
              "  'its',\n",
              "  'symptoms',\n",
              "  'resolved',\n",
              "  'after',\n",
              "  'stopping',\n",
              "  'clomipramine',\n",
              "  'but',\n",
              "  'before',\n",
              "  'Clozapine',\n",
              "  'has',\n",
              "  'been',\n",
              "  'restarted',\n",
              "  'eight',\n",
              "  'days',\n",
              "  'later.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 494
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ9JePuCpV0J",
        "outputId": "0a404470-c494-45a1-d0bb-af574c6a49fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_test = [sent2features_cus(s) for s in sent]"
      ],
      "outputs": [],
      "metadata": {
        "id": "3wgaNfVxtl5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'rarely',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'eboprofen',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'fen'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'causes',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'eboprofen',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'rarely',\n",
              "   'word[-2:]': 'ly',\n",
              "   'word[-3:]': 'ely'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'adverse',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'rarely',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'causes',\n",
              "   'word[-2:]': 'es',\n",
              "   'word[-3:]': 'ses'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'reactions',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'causes',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'adverse',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'rse'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'adverse',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'reactions',\n",
              "   'word[-2:]': 'ns',\n",
              "   'word[-3:]': 'ons'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'gastrointestinal',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'reactions',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'tract,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'gastrointestinal',\n",
              "   'word[-2:]': 'al',\n",
              "   'word[-3:]': 'nal'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'but',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'gastrointestinal',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'tract,',\n",
              "   'word[-2:]': 't,',\n",
              "   'word[-3:]': 'ct,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'is',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'tract,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'but',\n",
              "   'word[-2:]': 'ut',\n",
              "   'word[-3:]': 'but'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'involved',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'but',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'is',\n",
              "   'word[-2:]': 'is',\n",
              "   'word[-3:]': 'is'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'is',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'involved',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ved'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'systemic',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'involved',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'and',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'systemic',\n",
              "   'word[-2:]': 'ic',\n",
              "   'word[-3:]': 'mic'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'local',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'systemic',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'and',\n",
              "   'word[-2:]': 'nd',\n",
              "   'word[-3:]': 'and'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'side',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'and',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'local',\n",
              "   'word[-2:]': 'al',\n",
              "   'word[-3:]': 'cal'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'effects',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'local',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'side',\n",
              "   'word[-2:]': 'de',\n",
              "   'word[-3:]': 'ide'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'side',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'effects',\n",
              "   'word[-2:]': 'ts',\n",
              "   'word[-3:]': 'cts'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'lupus',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'effects',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'patients.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'lupus',\n",
              "   'word[-2:]': 'us',\n",
              "   'word[-3:]': 'pus'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'lupus',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'patients.',\n",
              "   'word[-2:]': 's.',\n",
              "   'word[-3:]': 'ts.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'our',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'to',\n",
              "   'word[-2:]': 'To',\n",
              "   'word[-3:]': 'To'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'knowledge,',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'to',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'our',\n",
              "   'word[-2:]': 'ur',\n",
              "   'word[-3:]': 'our'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'this',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'our',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'knowledge,',\n",
              "   'word[-2:]': 'e,',\n",
              "   'word[-3:]': 'ge,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'recurrence',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'knowledge,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'this',\n",
              "   'word[-2:]': 'is',\n",
              "   'word[-3:]': 'his'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'this',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'recurrence',\n",
              "   'word[-2:]': 'ce',\n",
              "   'word[-3:]': 'nce'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'amiodarone',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'recurrence',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'pulmonary',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'amiodarone',\n",
              "   'word[-2:]': 'ne',\n",
              "   'word[-3:]': 'one'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'toxicity',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'amiodarone',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'pulmonary',\n",
              "   'word[-2:]': 'ry',\n",
              "   'word[-3:]': 'ary'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'pulmonary',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'toxicity',\n",
              "   'word[-2:]': 'ty',\n",
              "   'word[-3:]': 'ity'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'not',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'toxicity',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'not',\n",
              "   'word[-2:]': 'ot',\n",
              "   'word[-3:]': 'not'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'previously',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'not',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'informed.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'previously',\n",
              "   'word[-2:]': 'ly',\n",
              "   'word[-3:]': 'sly'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'previously',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'informed.',\n",
              "   'word[-2:]': 'd.',\n",
              "   'word[-3:]': 'ed.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'describe',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'we',\n",
              "   'word[-2:]': 'We',\n",
              "   'word[-3:]': 'We'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'the',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'we',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'describe',\n",
              "   'word[-2:]': 'be',\n",
              "   'word[-3:]': 'ibe'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'development',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'describe',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'the'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'development',\n",
              "   'word[-2:]': 'nt',\n",
              "   'word[-3:]': 'ent'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'cutaneous',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'development',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'scleroderm',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'cutaneous',\n",
              "   'word[-2:]': 'us',\n",
              "   'word[-3:]': 'ous'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'cutaneous',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'scleroderm',\n",
              "   'word[-2:]': 'rm',\n",
              "   'word[-3:]': 'erm'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': '3',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'scleroderm',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'patients',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': True,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': '3',\n",
              "   'word[-2:]': '3',\n",
              "   'word[-3:]': '3'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'coinciding',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': '3',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'patients',\n",
              "   'word[-2:]': 'ts',\n",
              "   'word[-3:]': 'nts'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'with',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'patients',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'coinciding',\n",
              "   'word[-2:]': 'ng',\n",
              "   'word[-3:]': 'ing'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'the',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'coinciding',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'with',\n",
              "   'word[-2:]': 'th',\n",
              "   'word[-3:]': 'ith'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'use',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'with',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'the'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'use',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'use'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'low',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'use',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'cumulative',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'low',\n",
              "   'word[-2:]': 'ow',\n",
              "   'word[-3:]': 'low'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'low',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'low',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'cumulative',\n",
              "   'word[-2:]': 've',\n",
              "   'word[-3:]': 'ive'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'dose',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'cumulative',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'low',\n",
              "   'word[-2:]': 'ow',\n",
              "   'word[-3:]': 'low'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'bleomycin',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'low',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'dose',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'ose'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'less',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'dose',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'bleomycin',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'cin'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'than',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'bleomycin',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'less',\n",
              "   'word[-2:]': 'ss',\n",
              "   'word[-3:]': 'ess'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': '100',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'less',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'than',\n",
              "   'word[-2:]': 'an',\n",
              "   'word[-3:]': 'han'},\n",
              "  {'+1:word.istitle()': True,\n",
              "   '+1:word.isupper()': True,\n",
              "   '+1:word.lower()': 'u.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'than',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': True,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': '100',\n",
              "   'word[-2:]': '00',\n",
              "   'word[-3:]': '100'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': '100',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': True,\n",
              "   'word.lower()': 'u.',\n",
              "   'word[-2:]': 'U.',\n",
              "   'word[-3:]': 'U.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'few',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'only',\n",
              "   'word[-2:]': 'ly',\n",
              "   'word[-3:]': 'nly'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'reports',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'only',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'few',\n",
              "   'word[-2:]': 'ew',\n",
              "   'word[-3:]': 'few'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'exist',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'few',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'reports',\n",
              "   'word[-2:]': 'ts',\n",
              "   'word[-3:]': 'rts'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'on',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'reports',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'exist',\n",
              "   'word[-2:]': 'st',\n",
              "   'word[-3:]': 'ist'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'iodine-induced',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'exist',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'on',\n",
              "   'word[-2:]': 'on',\n",
              "   'word[-3:]': 'on'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hypothyroidism',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'on',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'iodine-induced',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ced'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'after',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'iodine-induced',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hypothyroidism',\n",
              "   'word[-2:]': 'sm',\n",
              "   'word[-3:]': 'ism'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'a',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hypothyroidism',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'after',\n",
              "   'word[-2:]': 'er',\n",
              "   'word[-3:]': 'ter'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'single',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'after',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'a',\n",
              "   'word[-3:]': 'a'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'injection',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'single',\n",
              "   'word[-2:]': 'le',\n",
              "   'word[-3:]': 'gle'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'single',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'injection',\n",
              "   'word[-2:]': 'on',\n",
              "   'word[-3:]': 'ion'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'the',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'injection',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'iodized',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'the'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'radiopaque',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'iodized',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'zed'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'dye',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'iodized',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'radiopaque',\n",
              "   'word[-2:]': 'ue',\n",
              "   'word[-3:]': 'que'},\n",
              "  {'+1:word.istitle()': True,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'lipiodol.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'radiopaque',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'dye',\n",
              "   'word[-2:]': 'ye',\n",
              "   'word[-3:]': 'dye'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'dye',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'lipiodol.',\n",
              "   'word[-2:]': 'l.',\n",
              "   'word[-3:]': 'ol.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'fatal',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': True,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'A',\n",
              "   'word[-3:]': 'A'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'case',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': True,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'fatal',\n",
              "   'word[-2:]': 'al',\n",
              "   'word[-3:]': 'tal'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'fatal',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'case',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'ase'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'theophylline',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'case',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'intoxication.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'theophylline',\n",
              "   'word[-2:]': 'ne',\n",
              "   'word[-3:]': 'ine'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'theophylline',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'intoxication.',\n",
              "   'word[-2:]': 'n.',\n",
              "   'word[-3:]': 'on.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'meeting',\n",
              "   'word[-2:]': 'ng',\n",
              "   'word[-3:]': 'ing'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'granulocytosis,',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'meeting',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'eosinophilic,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'granulocytosis,',\n",
              "   'word[-2:]': 's,',\n",
              "   'word[-3:]': 'is,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'skin',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'granulocytosis,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'eosinophilic,',\n",
              "   'word[-2:]': 'c,',\n",
              "   'word[-3:]': 'ic,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'reaction',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'eosinophilic,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'skin',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'kin'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'and',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'skin',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'reaction',\n",
              "   'word[-2:]': 'on',\n",
              "   'word[-3:]': 'ion'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hepatitis,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'reaction',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'and',\n",
              "   'word[-2:]': 'nd',\n",
              "   'word[-3:]': 'and'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'and',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hepatitis,',\n",
              "   'word[-2:]': 's,',\n",
              "   'word[-3:]': 'is,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hepatitis,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'reported',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'reported',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ted'},\n",
              "  {'+1:word.istitle()': True,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'propylthiova',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'reported',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': True,\n",
              "   '+1:word.lower()': '(ptu)',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'propylthiova',\n",
              "   'word[-2:]': 'va',\n",
              "   'word[-3:]': 'ova'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'therapy',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'propylthiova',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': True,\n",
              "   'word.lower()': '(ptu)',\n",
              "   'word[-2:]': 'U)',\n",
              "   'word[-3:]': 'TU)'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'for',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': True,\n",
              "   '-1:word.lower()': '(ptu)',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'therapy',\n",
              "   'word[-2:]': 'py',\n",
              "   'word[-3:]': 'apy'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'tyrotoxycycles',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'therapy',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'for',\n",
              "   'word[-2:]': 'or',\n",
              "   'word[-3:]': 'for'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'for',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'tyrotoxycycles',\n",
              "   'word[-2:]': 'es',\n",
              "   'word[-3:]': 'les'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'black',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'tyrotoxycycles',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'women',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'black',\n",
              "   'word[-2:]': 'ck',\n",
              "   'word[-3:]': 'ack'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'aged',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'black',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'women',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'men'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': '47.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'women',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'aged',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ged'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'aged',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': '47.',\n",
              "   'word[-2:]': '7.',\n",
              "   'word[-3:]': '47.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'a',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'as',\n",
              "   'word[-2:]': 'As',\n",
              "   'word[-3:]': 'As'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'result,',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'as',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'a',\n",
              "   'word[-3:]': 'a'},\n",
              "  {'+1:word.istitle()': True,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'amantadine',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'result,',\n",
              "   'word[-2:]': 't,',\n",
              "   'word[-3:]': 'lt,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'result,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'amantadine',\n",
              "   'word[-2:]': 'ne',\n",
              "   'word[-3:]': 'ine'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'amantadine',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'permanently',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'disturbed',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'permanently',\n",
              "   'word[-2:]': 'ly',\n",
              "   'word[-3:]': 'tly'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'and',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'permanently',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'disturbed',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'bed'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'the',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'disturbed',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'and',\n",
              "   'word[-2:]': 'nd',\n",
              "   'word[-3:]': 'and'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'cornea',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'and',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'the'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'cornea',\n",
              "   'word[-2:]': 'ea',\n",
              "   'word[-3:]': 'nea'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'renewed',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'cornea',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'again.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'renewed',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'wed'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'renewed',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'again.',\n",
              "   'word[-2:]': 'n.',\n",
              "   'word[-3:]': 'in.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'most',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'The'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'likely',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'most',\n",
              "   'word[-2:]': 'st',\n",
              "   'word[-3:]': 'ost'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'cause',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'most',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'likely',\n",
              "   'word[-2:]': 'ly',\n",
              "   'word[-3:]': 'ely'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'likely',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'cause',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'use'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hepatic',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'cause',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'insufficiency',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hepatic',\n",
              "   'word[-2:]': 'ic',\n",
              "   'word[-3:]': 'tic'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hepatic',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'insufficiency',\n",
              "   'word[-2:]': 'cy',\n",
              "   'word[-3:]': 'ncy'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'this',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'insufficiency',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'patient',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'this',\n",
              "   'word[-2:]': 'is',\n",
              "   'word[-3:]': 'his'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'was,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'this',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'patient',\n",
              "   'word[-2:]': 'nt',\n",
              "   'word[-3:]': 'ent'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'therefore,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'patient',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'was,',\n",
              "   'word[-2:]': 's,',\n",
              "   'word[-3:]': 'as,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'clarithromycin,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'was,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'therefore,',\n",
              "   'word[-2:]': 'e,',\n",
              "   'word[-3:]': 're,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'which',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'therefore,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'clarithromycin,',\n",
              "   'word[-2:]': 'n,',\n",
              "   'word[-3:]': 'in,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'is',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'clarithromycin,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'which',\n",
              "   'word[-2:]': 'ch',\n",
              "   'word[-3:]': 'ich'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'subjected',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'which',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'is',\n",
              "   'word[-2:]': 'is',\n",
              "   'word[-3:]': 'is'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'to',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'is',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'subjected',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ted'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'a',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'subjected',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'to',\n",
              "   'word[-2:]': 'to',\n",
              "   'word[-3:]': 'to'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hepatic',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'to',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'a',\n",
              "   'word[-3:]': 'a'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'metabolism',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hepatic',\n",
              "   'word[-2:]': 'ic',\n",
              "   'word[-3:]': 'tic'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'and',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hepatic',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'metabolism',\n",
              "   'word[-2:]': 'sm',\n",
              "   'word[-3:]': 'ism'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'metabolism',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'and',\n",
              "   'word[-2:]': 'nd',\n",
              "   'word[-3:]': 'and'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'and',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'reported',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'that',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'reported',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ted'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'it',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'reported',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'that',\n",
              "   'word[-2:]': 'at',\n",
              "   'word[-3:]': 'hat'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'causes',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'that',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'it',\n",
              "   'word[-2:]': 'it',\n",
              "   'word[-3:]': 'it'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'fulminating',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'it',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'causes',\n",
              "   'word[-2:]': 'es',\n",
              "   'word[-3:]': 'ses'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'liver',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'causes',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'fulminating',\n",
              "   'word[-2:]': 'ng',\n",
              "   'word[-3:]': 'ing'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'failure.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'fulminating',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'liver',\n",
              "   'word[-2:]': 'er',\n",
              "   'word[-3:]': 'ver'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'liver',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'failure.',\n",
              "   'word[-2:]': 'e.',\n",
              "   'word[-3:]': 're.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'mechanism',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'The'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'mechanism',\n",
              "   'word[-2:]': 'sm',\n",
              "   'word[-3:]': 'ism'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'decrease',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'mechanism',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'decrease',\n",
              "   'word[-2:]': 'se',\n",
              "   'word[-3:]': 'ase'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'potassium',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'decrease',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'plasma',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'potassium',\n",
              "   'word[-2:]': 'um',\n",
              "   'word[-3:]': 'ium'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'induced',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'potassium',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'plasma',\n",
              "   'word[-2:]': 'ma',\n",
              "   'word[-3:]': 'sma'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'by',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'plasma',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'induced',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ced'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'phosphate',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'induced',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'by',\n",
              "   'word[-2:]': 'by',\n",
              "   'word[-3:]': 'by'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'treatment',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'by',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'phosphate',\n",
              "   'word[-2:]': 'te',\n",
              "   'word[-3:]': 'ate'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'was',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'phosphate',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'treatment',\n",
              "   'word[-2:]': 'nt',\n",
              "   'word[-3:]': 'ent'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'investigated',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'treatment',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'was',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'was'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'in',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'was',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'investigated',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ted'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'a',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'investigated',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'in',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'in'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': '24-year',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'in',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'a',\n",
              "   'word[-3:]': 'a'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hypertensive',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': '24-year',\n",
              "   'word[-2:]': 'ar',\n",
              "   'word[-3:]': 'ear'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'patient',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': '24-year',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hypertensive',\n",
              "   'word[-2:]': 've',\n",
              "   'word[-3:]': 'ive'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'with',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hypertensive',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'patient',\n",
              "   'word[-2:]': 'nt',\n",
              "   'word[-3:]': 'ent'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'hypophosphatemic',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'patient',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'with',\n",
              "   'word[-2:]': 'th',\n",
              "   'word[-3:]': 'ith'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'osteomalacia,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'with',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'hypophosphatemic',\n",
              "   'word[-2:]': 'ic',\n",
              "   'word[-3:]': 'mic'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'who',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'hypophosphatemic',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'osteomalacia,',\n",
              "   'word[-2:]': 'a,',\n",
              "   'word[-3:]': 'ia,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'was',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'osteomalacia,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'who',\n",
              "   'word[-2:]': 'ho',\n",
              "   'word[-3:]': 'who'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'the',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'who',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'was',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'was'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'youngest',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'was',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'the',\n",
              "   'word[-2:]': 'he',\n",
              "   'word[-3:]': 'the'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'the',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'youngest',\n",
              "   'word[-2:]': 'st',\n",
              "   'word[-3:]': 'est'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'four',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'youngest',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'patients,',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'four',\n",
              "   'word[-2:]': 'ur',\n",
              "   'word[-3:]': 'our'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'who',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'four',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'patients,',\n",
              "   'word[-2:]': 's,',\n",
              "   'word[-3:]': 'ts,'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'belonged',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'patients,',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'who',\n",
              "   'word[-2:]': 'ho',\n",
              "   'word[-3:]': 'who'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'to',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'who',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'belonged',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ged'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'a',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'belonged',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'to',\n",
              "   'word[-2:]': 'to',\n",
              "   'word[-3:]': 'to'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'number',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'to',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'a',\n",
              "   'word[-2:]': 'a',\n",
              "   'word[-3:]': 'a'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'a',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'number',\n",
              "   'word[-2:]': 'er',\n",
              "   'word[-3:]': 'ber'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': '23',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'number',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'numbers',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': True,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': '23',\n",
              "   'word[-2:]': '23',\n",
              "   'word[-3:]': '23'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'of',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': '23',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'numbers',\n",
              "   'word[-2:]': 'rs',\n",
              "   'word[-3:]': 'ers'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'five',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'numbers',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'of',\n",
              "   'word[-2:]': 'of',\n",
              "   'word[-3:]': 'of'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'generations.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'of',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'five',\n",
              "   'word[-2:]': 've',\n",
              "   'word[-3:]': 'ive'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'five',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'generations.',\n",
              "   'word[-2:]': 's.',\n",
              "   'word[-3:]': 'ns.'}],\n",
              " [{'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   'BOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'it',\n",
              "   'word[-2:]': 'It',\n",
              "   'word[-3:]': 'It'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'it',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'diagnosed',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'with',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'diagnosed',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'sed'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'possible',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'diagnosed',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'with',\n",
              "   'word[-2:]': 'th',\n",
              "   'word[-3:]': 'ith'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'serotonin',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'with',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'possible',\n",
              "   'word[-2:]': 'le',\n",
              "   'word[-3:]': 'ble'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'syndrome;',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'possible',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'serotonin',\n",
              "   'word[-2:]': 'in',\n",
              "   'word[-3:]': 'nin'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'its',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'serotonin',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'syndrome;',\n",
              "   'word[-2:]': 'e;',\n",
              "   'word[-3:]': 'me;'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'symptoms',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'syndrome;',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'its',\n",
              "   'word[-2:]': 'ts',\n",
              "   'word[-3:]': 'its'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'resolved',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'its',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'symptoms',\n",
              "   'word[-2:]': 'ms',\n",
              "   'word[-3:]': 'oms'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'after',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'symptoms',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'resolved',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ved'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'stopping',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'resolved',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'after',\n",
              "   'word[-2:]': 'er',\n",
              "   'word[-3:]': 'ter'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'clomipramine',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'after',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'stopping',\n",
              "   'word[-2:]': 'ng',\n",
              "   'word[-3:]': 'ing'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'but',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'stopping',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'clomipramine',\n",
              "   'word[-2:]': 'ne',\n",
              "   'word[-3:]': 'ine'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'before',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'clomipramine',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'but',\n",
              "   'word[-2:]': 'ut',\n",
              "   'word[-3:]': 'but'},\n",
              "  {'+1:word.istitle()': True,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'clozapine',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'but',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'before',\n",
              "   'word[-2:]': 're',\n",
              "   'word[-3:]': 'ore'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'has',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'before',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': True,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'clozapine',\n",
              "   'word[-2:]': 'ne',\n",
              "   'word[-3:]': 'ine'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'been',\n",
              "   '-1:word.istitle()': True,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'clozapine',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'has',\n",
              "   'word[-2:]': 'as',\n",
              "   'word[-3:]': 'has'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'restarted',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'has',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'been',\n",
              "   'word[-2:]': 'en',\n",
              "   'word[-3:]': 'een'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'eight',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'been',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'restarted',\n",
              "   'word[-2:]': 'ed',\n",
              "   'word[-3:]': 'ted'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'days',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'restarted',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'eight',\n",
              "   'word[-2:]': 'ht',\n",
              "   'word[-3:]': 'ght'},\n",
              "  {'+1:word.istitle()': False,\n",
              "   '+1:word.isupper()': False,\n",
              "   '+1:word.lower()': 'later.',\n",
              "   '-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'eight',\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'days',\n",
              "   'word[-2:]': 'ys',\n",
              "   'word[-3:]': 'ays'},\n",
              "  {'-1:word.istitle()': False,\n",
              "   '-1:word.isupper()': False,\n",
              "   '-1:word.lower()': 'days',\n",
              "   'EOS': True,\n",
              "   'bias': 1.0,\n",
              "   'word.isdigit()': False,\n",
              "   'word.istitle()': False,\n",
              "   'word.isupper()': False,\n",
              "   'word.lower()': 'later.',\n",
              "   'word[-2:]': 'r.',\n",
              "   'word[-3:]': 'er.'}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 496
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI1GJRfstwMb",
        "outputId": "dc6a3bfa-1338-4289-e26b-34ce1b8243c2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions = ner_model.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MnsdawkRrSpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Final prediction of our model on the list of 10 sample sentences\n",
        "predictions"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DOSAGE',\n",
              "  'O',\n",
              "  'B-DRUG',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'B-DRUG', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 498
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrWzcZXTrdhk",
        "outputId": "8f7ba2a2-2378-4bfd-9361-06abb3d104da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**\n",
        "From the above result, it seems that our model can recognize a proportion of word and classify those words with the corresponding tag. However, since the model performance is not that sufficient, false-tagging and missing information is inevitable, but we can improve this model if we can define more complex feature extracion rules, tuning our CRF model with more hyperparameter or collect more data."
      ],
      "metadata": {
        "id": "s9_KiHFfuDz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "ZYLy8Y5d8Tv3"
      }
    }
  ]
}